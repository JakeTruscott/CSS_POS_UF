<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Truscott (Spring 2026)" />


<title>Topic Models</title>

<script src="topic_models_files/header-attrs-2.28/header-attrs.js"></script>
<script src="topic_models_files/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="topic_models_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="topic_models_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="topic_models_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="topic_models_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="topic_models_files/navigation-1.1/tabsets.js"></script>
<link href="topic_models_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="topic_models_files/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div id="header">



<h1 class="title toc-ignore">Topic Models</h1>
<h3 class="subtitle">POS6933: Computational Social Science</h3>
<h4 class="author">Truscott (Spring 2026)</h4>

</div>


<hr />
<div id="topic-models" class="section level2">
<h2>Topic Models</h2>
<p>Recall that one of our first exercises using text as data was to
analyze State of the Union addresses by former presidents – particularly
as it relates to concepts like the military and the economy. To do this,
we made at least two important assumptions:</p>
<ol style="list-style-type: decimal">
<li><p>Presidents may touch on various policy areas and themes
throughout these speeches.</p></li>
<li><p>Even though they may draw from different perspectives and
contexts, we can define a word or assert a general vocabulary to
identify those thematic elements – e.g., I can use terms like
<em>navy</em>, <em>army</em>, <em>marines</em>, etc. to reasonably
identify periods where the president is discussing military
matters.</p></li>
</ol>
<p>If we were to apply a clustering algorithm to these speeches, we may
be incidentally obscuring our ability to correctly identify these
various discussion points. Even clustering algorithms that use <em>soft
partitioning</em> are likely to draw documents towards a single cluster
center. But when we have documents where themes and other distinct
literary elements are in flux throughout, we may want to instead rely on
topic models.</p>
<p><strong>Topic Models</strong> are similar to clustering methods with
an important caveat: <em>rather than assign each document to only one
cluster, topic models assign each document with proportional membership
to all categories (topics). That is, topic models suppose that each
document is a mixture across categories – a mixed membership model</em>
(GSR Ch. 13). The key benefit here is that we don’t need a single topic
to be representative an entire document on its own. For instance, in
trying to identify how presidents may discuss the economy, topic models
may help us understand this through the lens of more discrete items like
the welfare state, taxation, foreign trade or other topics within the
broader scope of discussion related to economic policy – we don’t need
to say that only one of these should be used to discuss a speech (like a
SOTU address) that touches on all of them!</p>
</div>
<div id="latent-dirichlet-allocation" class="section level2">
<h2>Latent Dirichlet Allocation</h2>
<p>Much like how k-means is the canonical clustering algorithm, Latent
Dirichlet Allocation (LDA) is the canonical topic model. First
introduced in 2003, LDA is a generative probabilistic model – meaning
that it explicitly posits a data generating process for documents where
documents are mixtures of latent topics and words are drawn conditional
on those topics. In particular, it tries to recover:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Document-Topic Distributions</strong> – where each
document is represented a distribution over (perhaps multiple) different
topics, each with a certain probability.</p></li>
<li><p><strong>Topic-Word Distributions</strong> – where each topic is
represented as a distribution over words, meaning that each topic is
defined by a set of words (again all with an associated probability of
appearing in that topic).</p></li>
</ol>
<ul>
<li>Document Index = <span class="math inline">\(i\)</span></li>
<li>Topic Index = <span class="math inline">\(K\)</span></li>
<li>Word Position In Document (<span class="math inline">\(i\)</span>) =
<span class="math inline">\(m\)</span></li>
<li>Observed Word = <span class="math inline">\(W_{im}\)</span></li>
<li>Document-Topic Weights: <span
class="math inline">\(\pi_{ik}\)</span> where <span
class="math inline">\(\sum_{K}\pi_{iK} =1\)</span> (All Sum to 1)</li>
</ul>
<p>As you might be able to infer, LDA assumes the document-topic <span
class="math inline">\(Z_{im}\)</span> and topic-word <span
class="math inline">\(W_{im}\)</span> distributions has a Dirichlet
prior and draws from a multinomial distribution, where:</p>
<p><span class="math display">\[
Z_{im} \sim \text{Multinomial}(1,\pi_i) \quad \text{Topic Indicator for
Each Word} \\
W_{im} \sim \text{Multinomial}(1, \mu{Z_{im}}) \quad \text{Observed Word
Token For Each Word Position}
\]</span> So the probability of observing a word token in a document
(<span class="math inline">\(W_{im} = j\)</span>) conditional on both
the document-topic weights (<span
class="math inline">\(\pi_{iK}\)</span>) and the topic-word
distributions (<span class="math inline">\(\mu_k\)</span>) is a weighted
average of topic-specific word probabilities, where the weights are
given by the document’s topic proportions (<span
class="math inline">\(\pi_{iK}\)</span>):</p>
<p><span class="math display">\[
p(W_{im} = j \mid \pi_i,\mu) = \sum_K\pi_{iK}\mu_{jK}
\]</span></p>
<div id="lda-example" class="section level3">
<h3>LDA Example:</h3>
<pre class="r"><code>library(topicmodels)
data(&quot;AssociatedPress&quot;)
dtm &lt;- AssociatedPress

lda_model &lt;- LDA(dtm, k = 5, method = &quot;Gibbs&quot;, control = list(seed = 1234)) # LDA w/ 5 Topics &amp; Gibbs Sampling 
topicmodels::terms(lda_model, 10) </code></pre>
<pre><code>##       Topic 1  Topic 2   Topic 3      Topic 4     Topic 5     
##  [1,] &quot;i&quot;      &quot;percent&quot; &quot;court&quot;      &quot;i&quot;         &quot;government&quot;
##  [2,] &quot;people&quot; &quot;million&quot; &quot;police&quot;     &quot;president&quot; &quot;soviet&quot;    
##  [3,] &quot;two&quot;    &quot;year&quot;    &quot;two&quot;        &quot;bush&quot;      &quot;united&quot;    
##  [4,] &quot;air&quot;    &quot;billion&quot; &quot;state&quot;      &quot;house&quot;     &quot;states&quot;    
##  [5,] &quot;years&quot;  &quot;new&quot;     &quot;case&quot;       &quot;new&quot;       &quot;two&quot;       
##  [6,] &quot;new&quot;    &quot;company&quot; &quot;years&quot;      &quot;committee&quot; &quot;military&quot;  
##  [7,] &quot;just&quot;   &quot;last&quot;    &quot;federal&quot;    &quot;congress&quot;  &quot;people&quot;    
##  [8,] &quot;city&quot;   &quot;market&quot;  &quot;department&quot; &quot;dukakis&quot;   &quot;police&quot;    
##  [9,] &quot;like&quot;   &quot;prices&quot;  &quot;attorney&quot;   &quot;national&quot;  &quot;union&quot;     
## [10,] &quot;first&quot;  &quot;stock&quot;   &quot;drug&quot;       &quot;campaign&quot;  &quot;officials&quot;</code></pre>
<pre class="r"><code>topic_probs &lt;- posterior(lda_model)$topics # Prob Document i Belongs to Topic K
print(round(topic_probs[c(1:10), c(1:5)], 2))</code></pre>
<pre><code>##          1    2    3    4    5
##  [1,] 0.20 0.05 0.61 0.06 0.08
##  [2,] 0.07 0.31 0.12 0.20 0.30
##  [3,] 0.29 0.10 0.44 0.08 0.08
##  [4,] 0.30 0.17 0.13 0.14 0.25
##  [5,] 0.28 0.14 0.18 0.26 0.15
##  [6,] 0.06 0.08 0.08 0.38 0.40
##  [7,] 0.22 0.30 0.21 0.11 0.16
##  [8,] 0.13 0.13 0.10 0.39 0.25
##  [9,] 0.25 0.19 0.18 0.18 0.21
## [10,] 0.18 0.13 0.11 0.27 0.30</code></pre>
<pre class="r"><code>word_probs &lt;- posterior(lda_model)$terms # Prob Word J in Topic K
head(round(word_probs[, 1:5], 5))   </code></pre>
<pre><code>##     aaron abandon abandoned abandoning abbott
## 1 0.00000 0.00000   0.00039      0e+00  0e+00
## 2 0.00000 0.00000   0.00000      0e+00  0e+00
## 3 0.00000 0.00000   0.00000      0e+00  1e-04
## 4 0.00011 0.00016   0.00001      7e-05  0e+00
## 5 0.00000 0.00000   0.00006      0e+00  0e+00</code></pre>
<hr />
</div>
</div>
<div id="structural-topic-models" class="section level2">
<h2>Structural Topic Models</h2>
<p><strong>GRS</strong> spend some time talking about upstream and
downstream structural methods (though we won’t get too bogged down in
it…), but there is a lot of merit to the Structural Topic Model (STM) –
which provides a mechanism to add covariates to help explain both topic
prevalence <span class="math inline">\(X^P_i\)</span> and topic content
<span class="math inline">\(X^c_i\)</span>. It works like a traditional
topic model but also lets you introduce information about the documents
themselves <span class="math inline">\(X^p_i\)</span>. For each
document, the model first decides how much of each topic is likely to
appear (topic prevalence) – this can be driven by features like
authorship, publication date, etc.</p>
<p>Then, for each word in the document, the model picks a topic
according to those proportions and generates the word from that topic.
What makes STM especially powerful is that the way topics are expressed
in words (topic content) can also shift depending on covariates (<span
class="math inline">\(X^c_i\)</span>). Not only can you see which topics
are more common in certain types of documents, but you can also see how
the language used to discuss a topic changes with different document
characteristics. It’s a way to combine topic discovery with
regression-style analysis, giving you richer insights into both what
topics are present and how they’re talked about.</p>
<div id="stm-example" class="section level3">
<h3>STM Example:</h3>
<pre class="r"><code>texts &lt;- apply(AssociatedPress, 1, function(x) {
  paste(rep(colnames(AssociatedPress), x), collapse = &quot; &quot;)
})

reduce_complexity &lt;- function(text){
  text &lt;- tolower(text) # Lower Case
  text &lt;- tm::removePunctuation(text) # Punctuation
  text &lt;- tm::removeNumbers(text) # Numbers
  text &lt;- removeWords(text, tm::stopwords(&quot;english&quot;)) # Stop Words
  text &lt;- unlist(stringr::str_split(text, &#39;\\s+&#39;)) # Tokenize 
  text &lt;- textstem::lemmatize_words(text) # Lemmatize
  text &lt;- paste(text, collapse = &#39; &#39;) # Re-Append
  text &lt;- gsub(&quot;\\s{2,}&quot;, &#39; &#39;, text) # 2 or More Spaces --&gt; One Space
  text &lt;- trimws(text) # White Space
  return(text)
} # Complexity Reduction (See Class 5!)

texts_reduced &lt;- vapply(texts, reduce_complexity, character(1))

corpus_reduced &lt;- VCorpus(VectorSource(texts_reduced))

dtm_reduced &lt;- DocumentTermMatrix(
  corpus_reduced,
  control = list(wordLengths = c(1, Inf))
)

dfm_ap &lt;- as.dfm(dtm_reduced)

docs_stm &lt;- convert(dfm_ap, to = &quot;stm&quot;)

meta &lt;- data.frame(dummy = rep(1, length(docs_stm$documents)))

stm_model &lt;- stm::stm(
  documents  = docs_stm$documents,
  vocab      = docs_stm$vocab,
  K          = 5,
  prevalence = ~1,
  data       = meta,
  init.type  = &quot;Spectral&quot;,
  seed       = 1234,
  max.em.its = 500,
  verbose    = FALSE
)

stm::labelTopics(stm_model, n = 10) # Top Words/Topic</code></pre>
<pre><code>## Topic 1 Top Words:
##       Highest Prob: court, year, case, charge, say, two, attorney, go, police, school 
##       FREX: court, attorney, judge, trial, sentence, justice, lawyer, book, mother, convict 
##       Lift: male, moore, souter, abrams, abyss, acquit, actress, adjourn, adkins, admission 
##       Score: court, attorney, sentence, trial, police, lawyer, judge, prison, jury, convict 
## Topic 2 Top Words:
##       Highest Prob: official, report, air, department, state, two, service, test, area, fire 
##       FREX: water, plane, flight, ship, accident, space, pilot, navy, pentagon, aircraft 
##       Lift: virus, airplane, aspirin, bay, bomber, cargo, carrier, creek, crow, defect 
##       Score: plane, flight, pilot, nasa, aircraft, shuttle, airline, accident, ship, pentagon 
## Topic 3 Top Words:
##       Highest Prob: percent, million, year, market, price, company, billion, trade, new, stock 
##       FREX: market, price, stock, dollar, sale, cent, index, yen, gold, investor 
##       Lift: chrysler, trader, troy, abboud, acquisition, acustar, aftertax, ag, alkaline, alltime 
##       Score: stock, cent, percent, price, market, yen, index, rate, dollar, billion 
## Topic 4 Top Words:
##       Highest Prob: soviet, government, official, people, police, state, unite, party, force, military 
##       FREX: soviet, army, troop, gorbachev, communist, soldier, rebel, israel, africa, israeli 
##       Lift: abductor, abu, afghanistan, africas, ahmed, alfredo, algeria, algerian, algiers, amal 
##       Score: soviet, communist, police, gorbachev, troop, minister, guerrilla, palestinian, party, soldier 
## Topic 5 Top Words:
##       Highest Prob: bush, president, state, house, year, vote, new, go, say, make 
##       FREX: bush, dukakis, republican, senate, budget, sen, democrat, rep, jackson, legislation 
##       Lift: cavazos, dmass, sens, ad, legislation, marlin, nbc, abcs, accomplishment, adhere 
##       Score: dukakis, bush, republican, tax, percent, campaign, poll, democratic, budget, vote</code></pre>
<pre class="r"><code>proportions &lt;- stm_model$theta # Document-Topic Proportions
round(proportions[1:10, ], 2)</code></pre>
<pre><code>##       [,1] [,2] [,3] [,4] [,5]
##  [1,] 0.86 0.05 0.00 0.08 0.01
##  [2,] 0.27 0.04 0.18 0.48 0.02
##  [3,] 0.83 0.02 0.04 0.09 0.01
##  [4,] 0.35 0.04 0.11 0.34 0.15
##  [5,] 0.57 0.04 0.02 0.02 0.35
##  [6,] 0.01 0.24 0.01 0.25 0.50
##  [7,] 0.11 0.44 0.27 0.13 0.05
##  [8,] 0.01 0.01 0.02 0.17 0.79
##  [9,] 0.06 0.81 0.04 0.05 0.04
## [10,] 0.03 0.04 0.04 0.54 0.35</code></pre>
<pre class="r"><code>topic_word_probs &lt;- exp(stm_model$beta$logbeta[[1]]) #Topic Word Probabilities
head(round(topic_word_probs[,1:5], 5))</code></pre>
<pre><code>##         [,1]    [,2]    [,3]    [,4]    [,5]
## [1,] 0.00079 0.00044 0.00032 0.00026 0.00009
## [2,] 0.00086 0.00000 0.00000 0.00014 0.00019
## [3,] 0.00078 0.00079 0.00029 0.00011 0.00004
## [4,] 0.00043 0.00041 0.00012 0.00000 0.00002
## [5,] 0.00071 0.00055 0.00021 0.00016 0.00001</code></pre>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
