unique_words = n_distinct(word)) %>%
rename('Chapter Name' = chapter_name,
'Word Count' = word_count,
'Unique Words' = unique_words)
) # As Tibble
oliver_twist <- tibble::as_tibble(
oliver_twist %>%
group_by(chapter_name) %>%
summarize(text = paste(text, collapse = " ")) %>%
tidytext::unnest_tokens(word, text) %>%
mutate(
chapter_name = paste0(
stringr::str_c(
stringr::str_split(chapter_name, "\\s+", simplify = TRUE)[, 1:10],
collapse = " "
),
"..."
)
) %>%    group_by(chapter_name) %>%
summarize(
word_count = n(),
unique_words = n_distinct(word)) %>%
rename('Chapter Name' = chapter_name,
'Word Count' = word_count,
'Unique Words' = unique_words)
) # As Tibble
oliver_twist
oliver_twist <- gutenberg_download(730) # Download Oliver Twist
chapter_ids <-  paste0('(', paste(paste0('CHAPTER ', as.character(as.roman(1:26)), '.' ), collapse = '|'), ')') # Roman Number Chapter IDs
oliver_twist <- oliver_twist %>%
mutate(chapter_start = ifelse(grepl(chapter_ids, text), 1, 0),  # Identify Chapter Starts
chapter_name = ifelse(chapter_start == 1, paste(text, lead(text)), NA),
chapter_name = ifelse(chapter_start == 1 & !lead(text, 2) == '', paste0(chapter_name, ' ', lead(text, 2)), chapter_name)) %>% # Name Chapters
filter(!lag(chapter_start) == 1) %>% # Remove Title Rows
tidyr::fill(chapter_name, .direction = 'down') %>% # Assign Chapter Down
filter(!is.na(chapter_name), !text %in% c('', ' '), !chapter_start == 1) %>% # Remove Header, Empty Rows, Chapter Start Row
rowwise() %>%
filter(!grepl(text, chapter_name, fixed = TRUE)) %>%
select(-c(chapter_start, gutenberg_id))
paste(oliver_twist$text[1:8], collapse = ' ')
tibble::as_tibble(
oliver_twist %>%
group_by(chapter_name) %>%
summarize(text = paste(text, collapse = " ")) %>%
tidytext::unnest_tokens(word, text) %>%
group_by(chapter_name) %>%
summarize(
word_count = n(),
unique_words = n_distinct(word)) %>%
rename('Chapter Name' = chapter_name,
'Word Count' = word_count,
'Unique Words' = unique_words)
) # As Tibble
tibble::as_tibble(
oliver_twist %>%
mutate(chapter_name = trimws(chapter_name))
group_by(chapter_name) %>%
tibble::as_tibble(
oliver_twist %>%
mutate(chapter_name = trimws(chapter_name)) %>%
group_by(chapter_name) %>%
summarize(text = paste(text, collapse = " ")) %>%
tidytext::unnest_tokens(word, text) %>%
group_by(chapter_name) %>%
summarize(
word_count = n(),
unique_words = n_distinct(word)) %>%
rename('Chapter Name' = chapter_name,
'Word Count' = word_count,
'Unique Words' = unique_words)
) # As Tibble
oliver_twist %>%
mutate(chapter_name = trimws(chapter_name),
chapter_name = tokenizers::tokenize_sentences(chapter_name))
c <- oliver_twist$chapter_name[1]
c
tokenizers::tokenize_sentences(c)
tokenizers::tokenize_characters(c)
tokenizers::tokenize_words(c)
tokenizers::tokenize_words(c)[3:10]
tokenizers::tokenize_words(c)[[3:10]]
tokenizers::tokenize_words(c)
tokenizers::tokenize_words(c)[[1]][3:10]
stringr::str_to_title(tokenizers::tokenize_words(c)[[1]][3:10])
paste0(stringr::str_to_title(tokenizers::tokenize_words(c)[[1]][3:10]))
paste(stringr::str_to_title(tokenizers::tokenize_words(c)[[1]][3:10]), collapse = ' ')
paste(c(stringr::str_to_title(tokenizers::tokenize_words(c)[[1]][3:10]), ' ...'), collapse = ' ')
paste(c(stringr::str_to_title(tokenizers::tokenize_words(c)[[1]][3:10]), '...'), collapse = ' ')
paste(c(stringr::str_to_title(tokenizers::tokenize_words(c)[[1]][1:10]), '...'), collapse = ' ')
head(c)
tibble::as_tibble(
oliver_twist %>%
mutate(chapter_name = trimws(chapter_name)) %>%
group_by(chapter_name) %>%
summarize(text = paste(text, collapse = " ")) %>%
tidytext::unnest_tokens(word, text) %>%
group_by(chapter_name) %>%
summarize(
word_count = n(),
unique_words = n_distinct(word)) %>%
rename('Chapter Name' = chapter_name,
'Word Count' = word_count,
'Unique Words' = unique_words)
) # As Tibble
tibble::as_tibble(
oliver_twist %>%
mutate(chapter_name = trimws(chapter_name)) %>%
group_by(chapter_name) %>%
summarize(text = paste(text, collapse = " ")) %>%
tidytext::unnest_tokens(word, text) %>%
mutate(
chapter_name = ifelse(
stringr::str_count(chapter_name, "\\S+") > 10,
paste0(
stringr::str_c(
stringr::str_split(chapter_name, "\\s+", simplify = TRUE)[, 1:10],
collapse = " "
),
"..."
),
chapter_name
)
)
group_by(chapter_name) %>%
tibble::as_tibble(
oliver_twist %>%
mutate(chapter_name = trimws(chapter_name)) %>%
group_by(chapter_name) %>%
summarize(text = paste(text, collapse = " ")) %>%
tidytext::unnest_tokens(word, text) %>%
mutate(
chapter_name = ifelse(
stringr::str_count(chapter_name, "\\S+") > 10,
paste0(
stringr::str_c(
stringr::str_split(chapter_name, "\\s+", simplify = TRUE)[, 1:10],
collapse = " "
),
"..."
),
chapter_name
)
) %>%
group_by(chapter_name) %>%
summarize(
word_count = n(),
unique_words = n_distinct(word)) %>%
rename('Chapter Name' = chapter_name,
'Word Count' = word_count,
'Unique Words' = unique_words)
) # As Tibble
tibble::as_tibble(
oliver_twist %>%
mutate(
chapter_name = trimws(chapter_name),
chapter_name = ifelse(
stringr::str_count(chapter_name, "\\S+") > 10,
paste0(
stringr::str_c(
stringr::str_split(chapter_name, "\\s+", simplify = TRUE)[, 1:10],
collapse = " "
),
"..."
),
chapter_name
)
) %>%
group_by(chapter_name) %>%
summarize(text = paste(text, collapse = " "), .groups = "drop") %>%
tidytext::unnest_tokens(word, text) %>%
group_by(chapter_name) %>%
summarize(
`Word Count` = n(),
`Unique Words` = n_distinct(word),
.groups = "drop"
) %>%
rename(`Chapter Name` = chapter_name)
)
tibble::as_tibble(
oliver_twist %>%
mutate(chapter_name = trimws(chapter_name),
chapter_name = ifelse(stringr::str_count(chapter_name, "\\S+") > 10,
paste0(stringr::str_c(stringr::str_split(chapter_name, "\\s+", simplify = TRUE)[, 1:10],
collapse = " "), "..."), chapter_name)) %>%
group_by(chapter_name) %>%
summarize(text = paste(text, collapse = " "), .groups = "drop") %>%
tidytext::unnest_tokens(word, text) %>%
group_by(chapter_name) %>%
summarize(
`Word Count` = n(),
`Unique Words` = n_distinct(word),
.groups = "drop"
) %>%
rename(`Chapter Name` = chapter_name)
)  # As Tibble
oliver_twist <- tibble::as_tibble(
oliver_twist %>%
mutate(chapter_name = trimws(chapter_name),
chapter_name = ifelse(stringr::str_count(chapter_name, "\\S+") > 10,
paste0(stringr::str_c(stringr::str_split(chapter_name, "\\s+", simplify = TRUE)[, 1:10],
collapse = " "), "..."), chapter_name)) %>%
group_by(chapter_name) %>%
summarize(text = paste(text, collapse = " "), .groups = "drop") %>%
tidytext::unnest_tokens(word, text) %>%
group_by(chapter_name) %>%
summarize(
`Word Count` = n(),
`Unique Words` = n_distinct(word),
.groups = "drop"
) %>%
rename(`Chapter Name` = chapter_name)
)  # As Tibble
stargazer::stargazer(oliver_twist, type = 'text', summary = F)
gutenberg_metadata
gutenberg_metadata %>% filter(author == 'Tolstoy')
gutenberg_metadata %>% filter(grepl('Tolstoy', author))
gutenberg_metadata %>%
filter(title == "War and Peace")
war_and_peace <- gutenberg_download(2600) # Download War & Peace
View(war_and_peace)
chapter_ids <-  paste0('(', paste(paste0('CHAPTER ', as.character(as.roman(1:26)), '.' ), collapse = '|'), ')') # Roman Number Chapter IDs
c <- war_and_peace %>%
mutate(chapter_start = ifelse(grepl(chapter_ids, text), 1, 0),  # Identify Chapter Starts
chapter_name = ifelse(chapter_start == 1, paste(text, lead(text)), NA),
chapter_name = ifelse(chapter_start == 1 & !lead(text, 2) == '', paste0(chapter_name, ' ', lead(text, 2)), chapter_name),
chapter_name = trimws(chapter_name)) %>% # Name Chapters
filter(!lag(chapter_start) == 1) %>% # Remove Title Rows
tidyr::fill(chapter_name, .direction = 'down') %>% # Assign Chapter Down
filter(!is.na(chapter_name), !text %in% c('', ' '), !chapter_start == 1) %>% # Remove Header, Empty Rows, Chapter Start Row
rowwise() %>%
filter(!grepl(text, chapter_name, fixed = TRUE)) %>%
select(-c(chapter_start, gutenberg_id))
View(c)
c <- war_and_peace %>%
mutate(chapter_start = ifelse(grepl(chapter_ids, text), 1, 0),  # Identify Chapter Starts
chapter_name = ifelse(chapter_start == 1, paste(text, lead(text)), NA),
chapter_name = ifelse(chapter_start == 1 & !lead(text, 2) == '', paste0(chapter_name, ' ', lead(text, 2)), chapter_name),
chapter_name = trimws(chapter_name)) # Name Chapters
View(c)
c <- war_and_peace %>%
mutate(chapter_start = ifelse(grepl(chapter_ids, text), 1, 0),  # Identify Chapter Starts
chapter_name = ifelse(chapter_start == 1, paste(text, lead(text)), NA),
chapter_name = ifelse(chapter_start == 1 & !lead(text, 2) == '', paste0(chapter_name, ' ', lead(text, 2)), chapter_name),
chapter_name = trimws(chapter_name)) %>% # Name Chapters
filter(!lag(chapter_start) == 1) %>% # Remove Title Rows
tidyr::fill(chapter_name, .direction = 'down') %>% # Assign Chapter Down
filter(!is.na(chapter_name), !text %in% c('', ' '), !chapter_start == 1) %>% # Remove Header, Empty Rows, Chapter Start Row
rowwise() %>%
filter(!grepl(text, chapter_name, fixed = TRUE)) %>%
select(-c(chapter_start, gutenberg_id))
chapter_ids <-  paste0('(', paste(paste0('$CHAPTER ', as.character(as.roman(1:26)), '.' ), collapse = '|'), ')') # Roman Number Chapter IDs
c <- war_and_peace %>%
mutate(chapter_start = ifelse(grepl(chapter_ids, text), 1, 0),  # Identify Chapter Starts
chapter_name = ifelse(chapter_start == 1, paste(text, lead(text)), NA),
chapter_name = ifelse(chapter_start == 1 & !lead(text, 2) == '', paste0(chapter_name, ' ', lead(text, 2)), chapter_name),
chapter_name = trimws(chapter_name)) %>% # Name Chapters
filter(!lag(chapter_start) == 1) %>% # Remove Title Rows
tidyr::fill(chapter_name, .direction = 'down') %>% # Assign Chapter Down
filter(!is.na(chapter_name), !text %in% c('', ' '), !chapter_start == 1) %>% # Remove Header, Empty Rows, Chapter Start Row
rowwise() %>%
filter(!grepl(text, chapter_name, fixed = TRUE)) %>%
select(-c(chapter_start, gutenberg_id))
chapter_ids <-  paste0('(', paste(paste0('^CHAPTER ', as.character(as.roman(1:26)), '.' ), collapse = '|'), ')') # Roman Number Chapter IDs
c <- war_and_peace %>%
mutate(chapter_start = ifelse(grepl(chapter_ids, text), 1, 0),  # Identify Chapter Starts
chapter_name = ifelse(chapter_start == 1, paste(text, lead(text)), NA),
chapter_name = ifelse(chapter_start == 1 & !lead(text, 2) == '', paste0(chapter_name, ' ', lead(text, 2)), chapter_name),
chapter_name = trimws(chapter_name)) %>% # Name Chapters
filter(!lag(chapter_start) == 1) %>% # Remove Title Rows
tidyr::fill(chapter_name, .direction = 'down') %>% # Assign Chapter Down
filter(!is.na(chapter_name), !text %in% c('', ' '), !chapter_start == 1) %>% # Remove Header, Empty Rows, Chapter Start Row
rowwise() %>%
filter(!grepl(text, chapter_name, fixed = TRUE)) %>%
select(-c(chapter_start, gutenberg_id))
c <- war_and_peace %>%
mutate(chapter_start = ifelse(grepl(chapter_ids, text), 1, 0),  # Identify Chapter Starts
chapter_name = ifelse(chapter_start == 1, paste(text, lead(text)), NA),
chapter_name = ifelse(chapter_start == 1 & !lead(text, 2) == '', paste0(chapter_name, ' ', lead(text, 2)), chapter_name),
chapter_name = trimws(chapter_name)) %>% # Name Chapters
filter(!lag(chapter_start) == 1) %>% # Remove Title Rows
tidyr::fill(chapter_name, .direction = 'down') # Assign Chapter Down
chapter_ids <-  paste0('(', paste(paste0('^CHAPTER ', as.character(as.roman(1:26))), collapse = '|'), ')') # Roman Number Chapter IDs
c <- war_and_peace %>%
mutate(chapter_start = ifelse(grepl(chapter_ids, text), 1, 0),  # Identify Chapter Starts
chapter_name = ifelse(chapter_start == 1, paste(text, lead(text)), NA),
chapter_name = ifelse(chapter_start == 1 & !lead(text, 2) == '', paste0(chapter_name, ' ', lead(text, 2)), chapter_name),
chapter_name = trimws(chapter_name)) %>% # Name Chapters
filter(!lag(chapter_start) == 1) %>% # Remove Title Rows
tidyr::fill(chapter_name, .direction = 'down') %>% # Assign Chapter Down
filter(!is.na(chapter_name), !text %in% c('', ' '), !chapter_start == 1) %>% # Remove Header, Empty Rows, Chapter Start Row
rowwise() %>%
filter(!grepl(text, chapter_name, fixed = TRUE)) %>%
select(-c(chapter_start, gutenberg_id))
c <- war_and_peace %>%
mutate(chapter_start = ifelse(grepl(chapter_ids, text), 1, 0),  # Identify Chapter Starts
chapter_name = ifelse(chapter_start == 1, paste(text, lead(text)), NA),
chapter_name = ifelse(chapter_start == 1 & !lead(text, 2) == '', paste0(chapter_name, ' ', lead(text, 2)), chapter_name),
chapter_name = trimws(chapter_name)) %>% # Name Chapters
filter(!lag(chapter_start) == 1) %>% # Remove Title Rows
tidyr::fill(chapter_name, .direction = 'down') # Assign Chapter Down
c <- war_and_peace %>%
mutate(chapter_start = ifelse(grepl(chapter_ids, text), 1, 0),  # Identify Chapter Starts
chapter_name = ifelse(chapter_start == 1, paste(text), NA)) %>% # Name Chapters
filter(!lag(chapter_start) == 1) %>% # Remove Title Rows
tidyr::fill(chapter_name, .direction = 'down') # Assign Chapter Down
c <- war_and_peace %>%
mutate(chapter_start = ifelse(grepl(chapter_ids, text), 1, 0),  # Identify Chapter Starts
chapter_name = ifelse(chapter_start == 1, paste(text), NA)) %>% # Name Chapters
filter(!lag(chapter_start) == 1) %>% # Remove Title Rows
tidyr::fill(chapter_name, .direction = 'down') %>% # Assign Chapter Down
filter(!is.na(chapter_name), !text %in% c('', ' '), !chapter_start == 1) %>% # Remove Header, Empty Rows, Chapter Start Row
rowwise() %>%
filter(!grepl(text, chapter_name, fixed = TRUE)) %>%
select(-c(chapter_start, gutenberg_id))
paste(war_and_peace$text[1:8], collapse = ' ')
war_and_peace <- war_and_peace %>%
mutate(chapter_start = ifelse(grepl(chapter_ids, text), 1, 0),  # Identify Chapter Starts
chapter_name = ifelse(chapter_start == 1, paste(text), NA)) %>% # Name Chapters
filter(!lag(chapter_start) == 1) %>% # Remove Title Rows
tidyr::fill(chapter_name, .direction = 'down') %>% # Assign Chapter Down
filter(!is.na(chapter_name), !text %in% c('', ' '), !chapter_start == 1) %>% # Remove Header, Empty Rows, Chapter Start Row
rowwise() %>%
filter(!grepl(text, chapter_name, fixed = TRUE)) %>%
select(-c(chapter_start, gutenberg_id))
paste(war_and_peace$text[1:8], collapse = ' ')
war_and_peace <- tibble::as_tibble(
war_and_peace %>%
mutate(chapter_name = trimws(chapter_name),
chapter_name = ifelse(stringr::str_count(chapter_name, "\\S+") > 10,
paste0(stringr::str_c(stringr::str_split(chapter_name, "\\s+", simplify = TRUE)[, 1:10],
collapse = " "), "..."), chapter_name)) %>%
group_by(chapter_name) %>%
summarize(text = paste(text, collapse = " "), .groups = "drop") %>%
tidytext::unnest_tokens(word, text) %>%
group_by(chapter_name) %>%
summarize(
`Word Count` = n(),
`Unique Words` = n_distinct(word),
.groups = "drop"
) %>%
rename(`Chapter Name` = chapter_name)
)  # As Tibble
stargazer::stargazer(war_and_peace, type = 'text', summary = F)
library(dplyr); library(ggplot2); library(cowplot); library(formatR); library(stargazer); library(parallel); library(doParallel)
knitr::opts_chunk$set(
warning = FALSE,
fig.align = "center",
comment = NA,
dev = "pdf",
size = "tiny",
tidy = TRUE,
tidy.opts=list(width.cutoff=50)
)
default_ggplot_theme  <- theme_minimal(base_size = 12) +
theme(
plot.title = element_text(hjust = 0.5, size = 12),
axis.title = element_text(size = 12, colour = 'black'),
axis.text = element_text(size = 10, colour = 'black'),
panel.background = element_rect(linewidth = 1, colour = 'black', fill = NA),
legend.position = 'bottom',
legend.background = element_rect(linewidth = 1, colour = 'black', fill = NA),
)
sample_vector <- c('Sample 1', 'Sample 2', 'Sample 3')
print(sample_vector)
stringr::str_extract_all(text, "\\b[a-zA-Z]+\\b") # All Text
text <- "This is a sample string with a date 2026-02-06, a time 14:30, an email test.user@example.com, and the number 42."
stringr::str_extract_all(text, "\\b[a-zA-Z]+\\b") # All Text
stringr::str_extract_all(text, "\\b\\d+\\b") # All Numbers
unlist(stringr::str_extract_all(text, "\\b\\d+\\b")) # All Numbers
stringr::str_extract_all(text, "\\b[a-zA-Z]+\\b") # All Text
unlist(stringr::str_extract_all(text, "\\b[a-zA-Z]+\\b")) # All Text
lorem_ipsum <- "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Maecenas scelerisque eros nec libero luctus, a gravida augue dictum. Integer sem est, malesuada nec mi ut, venenatis pellentesque massa. Mauris ac ex odio. Integer eget est lacus. Ut varius, sapien nec efficitur malesuada, sem lectus aliquet lacus, ac efficitur ipsum mauris vitae augue. Aliquam ornare faucibus nibh, a varius mauris mattis id. Nullam eu nibh aliquam, vestibulum neque sed, sagittis mi. Etiam blandit facilisis sagittis. Duis ut dolor sed nibh egestas porta. Aenean quis lorem nec augue semper convallis lacinia eget orci. Nam eget dolor tortor."
stringr::str_split(lorem_ipsum, pattern = '\\.')
stringr::str_split(lorem_ipsum, pattern = '\\. ')
sample(c('Pam', 'Kyle'), 10)
sample_data_frame <- data.frame(name = sample(c('Pam', 'Kyle'), 1:10))
sample_data_frame <- data.frame(name = sample(10, c('Pam', 'Kyle'), replace = F)
sample_data_frame
data.frame(name = sample(10, c('Pam', 'Kyle'), replace = F))
data.frame(name = sample(10, c('Pam', 'Kyle'), replace = T))
sample(c('Pam', 'Ron'), size = 10, replace = F)
sample(c('Pam', 'Ron'), size = 10, replace = T)
df <- data.frame(name = sample(c('Pam', 'Ron'), 10, replace = T),
sport = sample(c('Run', 'Golf', 10, replace = T)))
df <- data.frame(name = sample(c('Pam', 'Ron'), 10, replace = T),
sport = sample(c('Run', 'Golf'), 10, replace = T))
df
print(df)
df <- data.frame(name = sample(c('Pam', 'Ron'), 5, replace = T),
sport = sample(c('Run', 'Golf'), 5, replace = T))
print(df)
df %>% mutate(name = ifelse(grepl('am', name), gsub('am', 'amela', name)))
df %>% mutate(name = ifelse(grepl('am', name), gsub('am', 'amela', name), name))
string <- 'The quick brown fox jumps over the lazy dog'
gsub('quick', 'wild', string) # Replace Quick
grepl('quick brown', string, ignore.case = F)
s1 <- 'The cautious archivist indexed seven obscure manuscripts before dawn.'
s2 <- 'Tomorrow a reckless cyclist shattered records while racing before sunset.'
sentences <- c(s1, s2)
gsub('.*before ', '', gsub('\\.', '', sentences))
trimws(unlist(stringr::str_split(lorem_ipsum, pattern = '\\.')))[1:5]
trimws(unlist(stringr::str_split(lorem_ipsum, pattern = '\\.s+{}')))[1:5]
trimws(unlist(stringr::str_split(lorem_ipsum, pattern = '\\.s+')))[1:5]
trimws(unlist(stringr::str_split(lorem_ipsum, pattern = '\\.s{}')))[1:5]
trimws(unlist(stringr::str_split(lorem_ipsum, pattern = '\\.[[space]]')))[1:5]
trimws(unlist(stringr::str_split(lorem_ipsum, pattern = '\\.[[:space:]]')))[1:5]
unlist(stringr::str_split(lorem_ipsum, pattern = '\\.[[:space:]]'))[1:5]
damn_lies_corpus <- quanteda::corpus(damn_lies, text_field = "dialogue") # Create Corpus (Text = 'dialogue')
west_wing_script_location <- "https://raw.githubusercontent.com/JakeTruscott/CSS_POS_UF/main/docs/assets/replication_materials/class_4/supplemental_materials/West_Wing_S1_E21.txt" # Location of txt File on Github Repo
west_wing <- readLines(west_wing_script_location, warn = FALSE) # Read Txt from GitHub Repo
west_wing <- data.frame(unlist(west_wing)) %>%
setNames('text') # Unlist Script as Text
characters <- c('Josh', 'Toby', 'C.J.', 'Donna', 'Sam', 'Leo', 'Bartlet')  # Characters of Interests
character_regex <- paste0("^(", paste0(toupper(characters), collapse = "|"), ")$") #
damn_lies <-  west_wing %>%
mutate(character_line = ifelse(stringr::str_detect(text, character_regex), 1, 0), # If Character Found in Text
empty_row = ifelse(text == '', 1, 0), # If Row is Empty
first_entry = ifelse(character_line == 1, 1, NA)) %>% #
tidyr::fill(first_entry, .direction = 'down') %>% # Fill Down
filter(!is.na(first_entry)) %>% # Remove Empty Rows
select(-c(first_entry)) %>%
mutate(group = cumsum(character_line == 1)) %>%
group_by(group) %>%
mutate(to_keep = row_number() < which(empty_row == 1)[1] | is.na(which(empty_row == 1)[1])) %>%
ungroup() %>%
filter(to_keep) %>% # Removes Empty Lines
select(text, character_line) %>%
mutate(group = cumsum(character_line == 1)) %>%
group_by(group) %>%
summarise(
character = text[character_line == 1][1],
dialogue  = paste(text[-1], collapse = " "),
.groups = "drop") %>%
rename(id = group) %>%
select(character, dialogue, id) %>%
rowwise() %>%
mutate(word_count = stringr::str_count(dialogue, "\\S+")) %>% # Count Words
ungroup() %>%
filter(!word_count == 0) # Final Check
head(damn_lies, 10) # Print Sample of Rows
damn_lies_corpus <- quanteda::corpus(damn_lies, text_field = "dialogue") # Create Corpus (Text = 'dialogue')
summary(damn_lies_corpus[1:10]) # Inspect (Just First Couple of Rows)
damn_lies_corpus[[1]]
damn_lies_corpus[1]
damn_lies_corpus[1:10]
damn_lies_corpus[1]
docvars(damn_lies_corpus[1])
docvars(damn_lies_corpus)[1]
quanteda::docvars(damn_lies_corpus)
quanteda::docvars(damn_lies_corpus)[1]
quanteda::docvars(damn_lies_corpus[1])
texts_with_meta <- tibble(
doc_id = c("sentence_1", "sentence_2", "sentence_3"),
text = texts,
author = c('Josh', 'Leo', 'Toby'),
date = as.Date(c("2025-01-01", "2025-01-02", "2025-01-03"))
) # Create Metadata for Texts (Same as tm example!)
library(quanteda) # Load Quanteda
texts <- c(
"The quick brown fox jumps over the lazy dog.",
"Data science is revolutionizing the way we analyze information.",
"Text analysis in R is fun and informative!"
) # Sample Texts (as vector)
texts_with_meta <- tibble(
doc_id = c("sentence_1", "sentence_2", "sentence_3"),
text = texts,
author = c('Josh', 'Leo', 'Toby'),
date = as.Date(c("2025-01-01", "2025-01-02", "2025-01-03"))
) # Create Metadata for Texts (Same as tm example!)
quanteda_corpus <- corpus(texts_with_meta, text_field = "text")
library(scotustext) # Load
dobbs <- scotustext::oyez_transcript_search(docket = '19-1392', term = 2021)
getwd()
save(dobbs, file = 'class_4/data/dobbs_19-1392.rdata')
head(dobbs)
names(dobbbs)
names(dobbs)
head(dobbs)
dobbs %>%
filter(role == 'Justice') %>%
group_by(speaker) %>%
summarise(count = n())
dobbs %>%
filter(role == 'Justice') %>%
group_by(speaker) %>%
summarise(utterances = n()) %>%
arrange(utterances)
dobbs %>%
filter(role == 'Justice') %>%
group_by(speaker) %>%
summarise(utterances = n()) %>%
arrange(desc(utterances))
dobbs %>%
filter(role == 'Justice') %>%
group_by(speaker) %>%
summarize(text = paste(text, collapse = " "), .groups = "drop") %>%
tidytext::unnest_tokens(word, text) %>%
group_by(speaker) %>%
summarise(word_count = n())
dobbs %>%
filter(role == 'Justice') %>%
group_by(speaker) %>%
summarize(text = paste(text, collapse = " "), .groups = "drop") %>%
tidytext::unnest_tokens(word, text) %>%
group_by(speaker) %>%
summarise(word_count = n(), .groups = 'drop') %>%
arrange(desc(word_count))
dobbs <- get(load('https://raw.githubusercontent.com/JakeTruscott/CSS_POS_UF/refs/heads/main/docs/assets/replication_materials/class_4/data/dobbs_19-1392.rdata')) # Load Dobbs
dobbs <- get(load('class_4/data/dobbs_19-1392.rdata')) # Load Dobbs
getwd()
dobbs <- get(load('../class_4/data/dobbs_19-1392.rdata')) # Load Dobbs
dobbs <- get(load('../data/dobbs_19-1392.rdata')) # Load Dobbs
