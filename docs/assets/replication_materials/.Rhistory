rowwise() %>%
filter(!grepl(text, chapter_name, fixed = TRUE)) %>%
select(-c(chapter_start, gutenberg_id))
c <- war_and_peace %>%
mutate(chapter_start = ifelse(grepl(chapter_ids, text), 1, 0),  # Identify Chapter Starts
chapter_name = ifelse(chapter_start == 1, paste(text, lead(text)), NA),
chapter_name = ifelse(chapter_start == 1 & !lead(text, 2) == '', paste0(chapter_name, ' ', lead(text, 2)), chapter_name),
chapter_name = trimws(chapter_name)) %>% # Name Chapters
filter(!lag(chapter_start) == 1) %>% # Remove Title Rows
tidyr::fill(chapter_name, .direction = 'down') # Assign Chapter Down
c <- war_and_peace %>%
mutate(chapter_start = ifelse(grepl(chapter_ids, text), 1, 0),  # Identify Chapter Starts
chapter_name = ifelse(chapter_start == 1, paste(text), NA)) %>% # Name Chapters
filter(!lag(chapter_start) == 1) %>% # Remove Title Rows
tidyr::fill(chapter_name, .direction = 'down') # Assign Chapter Down
c <- war_and_peace %>%
mutate(chapter_start = ifelse(grepl(chapter_ids, text), 1, 0),  # Identify Chapter Starts
chapter_name = ifelse(chapter_start == 1, paste(text), NA)) %>% # Name Chapters
filter(!lag(chapter_start) == 1) %>% # Remove Title Rows
tidyr::fill(chapter_name, .direction = 'down') %>% # Assign Chapter Down
filter(!is.na(chapter_name), !text %in% c('', ' '), !chapter_start == 1) %>% # Remove Header, Empty Rows, Chapter Start Row
rowwise() %>%
filter(!grepl(text, chapter_name, fixed = TRUE)) %>%
select(-c(chapter_start, gutenberg_id))
paste(war_and_peace$text[1:8], collapse = ' ')
war_and_peace <- war_and_peace %>%
mutate(chapter_start = ifelse(grepl(chapter_ids, text), 1, 0),  # Identify Chapter Starts
chapter_name = ifelse(chapter_start == 1, paste(text), NA)) %>% # Name Chapters
filter(!lag(chapter_start) == 1) %>% # Remove Title Rows
tidyr::fill(chapter_name, .direction = 'down') %>% # Assign Chapter Down
filter(!is.na(chapter_name), !text %in% c('', ' '), !chapter_start == 1) %>% # Remove Header, Empty Rows, Chapter Start Row
rowwise() %>%
filter(!grepl(text, chapter_name, fixed = TRUE)) %>%
select(-c(chapter_start, gutenberg_id))
paste(war_and_peace$text[1:8], collapse = ' ')
war_and_peace <- tibble::as_tibble(
war_and_peace %>%
mutate(chapter_name = trimws(chapter_name),
chapter_name = ifelse(stringr::str_count(chapter_name, "\\S+") > 10,
paste0(stringr::str_c(stringr::str_split(chapter_name, "\\s+", simplify = TRUE)[, 1:10],
collapse = " "), "..."), chapter_name)) %>%
group_by(chapter_name) %>%
summarize(text = paste(text, collapse = " "), .groups = "drop") %>%
tidytext::unnest_tokens(word, text) %>%
group_by(chapter_name) %>%
summarize(
`Word Count` = n(),
`Unique Words` = n_distinct(word),
.groups = "drop"
) %>%
rename(`Chapter Name` = chapter_name)
)  # As Tibble
stargazer::stargazer(war_and_peace, type = 'text', summary = F)
library(dplyr); library(ggplot2); library(cowplot); library(formatR); library(stargazer); library(parallel); library(doParallel)
knitr::opts_chunk$set(
warning = FALSE,
fig.align = "center",
comment = NA,
dev = "pdf",
size = "tiny",
tidy = TRUE,
tidy.opts=list(width.cutoff=50)
)
default_ggplot_theme  <- theme_minimal(base_size = 12) +
theme(
plot.title = element_text(hjust = 0.5, size = 12),
axis.title = element_text(size = 12, colour = 'black'),
axis.text = element_text(size = 10, colour = 'black'),
panel.background = element_rect(linewidth = 1, colour = 'black', fill = NA),
legend.position = 'bottom',
legend.background = element_rect(linewidth = 1, colour = 'black', fill = NA),
)
sample_vector <- c('Sample 1', 'Sample 2', 'Sample 3')
print(sample_vector)
stringr::str_extract_all(text, "\\b[a-zA-Z]+\\b") # All Text
text <- "This is a sample string with a date 2026-02-06, a time 14:30, an email test.user@example.com, and the number 42."
stringr::str_extract_all(text, "\\b[a-zA-Z]+\\b") # All Text
stringr::str_extract_all(text, "\\b\\d+\\b") # All Numbers
unlist(stringr::str_extract_all(text, "\\b\\d+\\b")) # All Numbers
stringr::str_extract_all(text, "\\b[a-zA-Z]+\\b") # All Text
unlist(stringr::str_extract_all(text, "\\b[a-zA-Z]+\\b")) # All Text
lorem_ipsum <- "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Maecenas scelerisque eros nec libero luctus, a gravida augue dictum. Integer sem est, malesuada nec mi ut, venenatis pellentesque massa. Mauris ac ex odio. Integer eget est lacus. Ut varius, sapien nec efficitur malesuada, sem lectus aliquet lacus, ac efficitur ipsum mauris vitae augue. Aliquam ornare faucibus nibh, a varius mauris mattis id. Nullam eu nibh aliquam, vestibulum neque sed, sagittis mi. Etiam blandit facilisis sagittis. Duis ut dolor sed nibh egestas porta. Aenean quis lorem nec augue semper convallis lacinia eget orci. Nam eget dolor tortor."
stringr::str_split(lorem_ipsum, pattern = '\\.')
stringr::str_split(lorem_ipsum, pattern = '\\. ')
sample(c('Pam', 'Kyle'), 10)
sample_data_frame <- data.frame(name = sample(c('Pam', 'Kyle'), 1:10))
sample_data_frame <- data.frame(name = sample(10, c('Pam', 'Kyle'), replace = F)
sample_data_frame
data.frame(name = sample(10, c('Pam', 'Kyle'), replace = F))
data.frame(name = sample(10, c('Pam', 'Kyle'), replace = T))
sample(c('Pam', 'Ron'), size = 10, replace = F)
sample(c('Pam', 'Ron'), size = 10, replace = T)
df <- data.frame(name = sample(c('Pam', 'Ron'), 10, replace = T),
sport = sample(c('Run', 'Golf', 10, replace = T)))
df <- data.frame(name = sample(c('Pam', 'Ron'), 10, replace = T),
sport = sample(c('Run', 'Golf'), 10, replace = T))
df
print(df)
df <- data.frame(name = sample(c('Pam', 'Ron'), 5, replace = T),
sport = sample(c('Run', 'Golf'), 5, replace = T))
print(df)
df %>% mutate(name = ifelse(grepl('am', name), gsub('am', 'amela', name)))
df %>% mutate(name = ifelse(grepl('am', name), gsub('am', 'amela', name), name))
string <- 'The quick brown fox jumps over the lazy dog'
gsub('quick', 'wild', string) # Replace Quick
grepl('quick brown', string, ignore.case = F)
s1 <- 'The cautious archivist indexed seven obscure manuscripts before dawn.'
s2 <- 'Tomorrow a reckless cyclist shattered records while racing before sunset.'
sentences <- c(s1, s2)
gsub('.*before ', '', gsub('\\.', '', sentences))
trimws(unlist(stringr::str_split(lorem_ipsum, pattern = '\\.')))[1:5]
trimws(unlist(stringr::str_split(lorem_ipsum, pattern = '\\.s+{}')))[1:5]
trimws(unlist(stringr::str_split(lorem_ipsum, pattern = '\\.s+')))[1:5]
trimws(unlist(stringr::str_split(lorem_ipsum, pattern = '\\.s{}')))[1:5]
trimws(unlist(stringr::str_split(lorem_ipsum, pattern = '\\.[[space]]')))[1:5]
trimws(unlist(stringr::str_split(lorem_ipsum, pattern = '\\.[[:space:]]')))[1:5]
unlist(stringr::str_split(lorem_ipsum, pattern = '\\.[[:space:]]'))[1:5]
damn_lies_corpus <- quanteda::corpus(damn_lies, text_field = "dialogue") # Create Corpus (Text = 'dialogue')
west_wing_script_location <- "https://raw.githubusercontent.com/JakeTruscott/CSS_POS_UF/main/docs/assets/replication_materials/class_4/supplemental_materials/West_Wing_S1_E21.txt" # Location of txt File on Github Repo
west_wing <- readLines(west_wing_script_location, warn = FALSE) # Read Txt from GitHub Repo
west_wing <- data.frame(unlist(west_wing)) %>%
setNames('text') # Unlist Script as Text
characters <- c('Josh', 'Toby', 'C.J.', 'Donna', 'Sam', 'Leo', 'Bartlet')  # Characters of Interests
character_regex <- paste0("^(", paste0(toupper(characters), collapse = "|"), ")$") #
damn_lies <-  west_wing %>%
mutate(character_line = ifelse(stringr::str_detect(text, character_regex), 1, 0), # If Character Found in Text
empty_row = ifelse(text == '', 1, 0), # If Row is Empty
first_entry = ifelse(character_line == 1, 1, NA)) %>% #
tidyr::fill(first_entry, .direction = 'down') %>% # Fill Down
filter(!is.na(first_entry)) %>% # Remove Empty Rows
select(-c(first_entry)) %>%
mutate(group = cumsum(character_line == 1)) %>%
group_by(group) %>%
mutate(to_keep = row_number() < which(empty_row == 1)[1] | is.na(which(empty_row == 1)[1])) %>%
ungroup() %>%
filter(to_keep) %>% # Removes Empty Lines
select(text, character_line) %>%
mutate(group = cumsum(character_line == 1)) %>%
group_by(group) %>%
summarise(
character = text[character_line == 1][1],
dialogue  = paste(text[-1], collapse = " "),
.groups = "drop") %>%
rename(id = group) %>%
select(character, dialogue, id) %>%
rowwise() %>%
mutate(word_count = stringr::str_count(dialogue, "\\S+")) %>% # Count Words
ungroup() %>%
filter(!word_count == 0) # Final Check
head(damn_lies, 10) # Print Sample of Rows
damn_lies_corpus <- quanteda::corpus(damn_lies, text_field = "dialogue") # Create Corpus (Text = 'dialogue')
summary(damn_lies_corpus[1:10]) # Inspect (Just First Couple of Rows)
damn_lies_corpus[[1]]
damn_lies_corpus[1]
damn_lies_corpus[1:10]
damn_lies_corpus[1]
docvars(damn_lies_corpus[1])
docvars(damn_lies_corpus)[1]
quanteda::docvars(damn_lies_corpus)
quanteda::docvars(damn_lies_corpus)[1]
quanteda::docvars(damn_lies_corpus[1])
texts_with_meta <- tibble(
doc_id = c("sentence_1", "sentence_2", "sentence_3"),
text = texts,
author = c('Josh', 'Leo', 'Toby'),
date = as.Date(c("2025-01-01", "2025-01-02", "2025-01-03"))
) # Create Metadata for Texts (Same as tm example!)
library(quanteda) # Load Quanteda
texts <- c(
"The quick brown fox jumps over the lazy dog.",
"Data science is revolutionizing the way we analyze information.",
"Text analysis in R is fun and informative!"
) # Sample Texts (as vector)
texts_with_meta <- tibble(
doc_id = c("sentence_1", "sentence_2", "sentence_3"),
text = texts,
author = c('Josh', 'Leo', 'Toby'),
date = as.Date(c("2025-01-01", "2025-01-02", "2025-01-03"))
) # Create Metadata for Texts (Same as tm example!)
quanteda_corpus <- corpus(texts_with_meta, text_field = "text")
library(scotustext) # Load
dobbs <- scotustext::oyez_transcript_search(docket = '19-1392', term = 2021)
getwd()
save(dobbs, file = 'class_4/data/dobbs_19-1392.rdata')
head(dobbs)
names(dobbbs)
names(dobbs)
head(dobbs)
dobbs %>%
filter(role == 'Justice') %>%
group_by(speaker) %>%
summarise(count = n())
dobbs %>%
filter(role == 'Justice') %>%
group_by(speaker) %>%
summarise(utterances = n()) %>%
arrange(utterances)
dobbs %>%
filter(role == 'Justice') %>%
group_by(speaker) %>%
summarise(utterances = n()) %>%
arrange(desc(utterances))
dobbs %>%
filter(role == 'Justice') %>%
group_by(speaker) %>%
summarize(text = paste(text, collapse = " "), .groups = "drop") %>%
tidytext::unnest_tokens(word, text) %>%
group_by(speaker) %>%
summarise(word_count = n())
dobbs %>%
filter(role == 'Justice') %>%
group_by(speaker) %>%
summarize(text = paste(text, collapse = " "), .groups = "drop") %>%
tidytext::unnest_tokens(word, text) %>%
group_by(speaker) %>%
summarise(word_count = n(), .groups = 'drop') %>%
arrange(desc(word_count))
dobbs <- get(load('https://raw.githubusercontent.com/JakeTruscott/CSS_POS_UF/refs/heads/main/docs/assets/replication_materials/class_4/data/dobbs_19-1392.rdata')) # Load Dobbs
dobbs <- get(load('class_4/data/dobbs_19-1392.rdata')) # Load Dobbs
getwd()
dobbs <- get(load('../class_4/data/dobbs_19-1392.rdata')) # Load Dobbs
dobbs <- get(load('../data/dobbs_19-1392.rdata')) # Load Dobbs
library(dplyr); library(ggplot2); library(cowplot); library(formatR); library(stargazer); library(parallel); library(doParallel)
knitr::opts_chunk$set(
warning = FALSE,
fig.align = "center",
comment = NA,
dev = "pdf",
size = "tiny",
tidy = TRUE,
tidy.opts=list(width.cutoff=50),
R.options = list(width = 120)
)
default_ggplot_theme  <- theme_minimal(base_size = 12) +
theme(
plot.title = element_text(hjust = 0.5, size = 12),
axis.title = element_text(size = 12, colour = 'black'),
axis.text = element_text(size = 10, colour = 'black'),
panel.background = element_rect(linewidth = 1, colour = 'black', fill = NA),
legend.position = 'bottom',
legend.background = element_rect(linewidth = 1, colour = 'black', fill = NA),
)
west_wing_script_location <- "https://raw.githubusercontent.com/JakeTruscott/CSS_POS_UF/main/docs/assets/replication_materials/class_4/supplemental_materials/West_Wing_S1_E21.txt" # Location of txt File on Github Repo
west_wing <- readLines(west_wing_script_location, warn = FALSE) # Read Txt from GitHub Repo
head(west_wing)  # Print Head
west_wing <- data.frame(unlist(west_wing)) %>%
setNames('text') # Unlist Script as Text
characters <- c('Josh', 'Toby', 'C.J.', 'Donna', 'Sam', 'Leo', 'Bartlet')  # Characters of Interests
character_regex <- paste0("^(", paste0(toupper(characters), collapse = "|"), ")$") #
damn_lies <-  west_wing %>%
mutate(character_line = ifelse(stringr::str_detect(text, character_regex), 1, 0),
empty_row = ifelse(text == '', 1, 0),
first_entry = ifelse(character_line == 1, 1, NA)) %>%
tidyr::fill(first_entry, .direction = 'down') %>%
filter(!is.na(first_entry)) %>%
select(-c(first_entry)) %>%
mutate(group = cumsum(character_line == 1)) %>%
group_by(group) %>%
mutate(to_keep = row_number() < which(empty_row == 1)[1] | is.na(which(empty_row == 1)[1])) %>%
ungroup() %>%
filter(to_keep) %>%
select(text, character_line) %>%
mutate(group = cumsum(character_line == 1)) %>%
group_by(group) %>%
summarise(
character = text[character_line == 1][1],
dialogue  = paste(text[-1], collapse = " "),
.groups = "drop") %>%
rename(id = group) %>%
select(character, dialogue, id) %>%
rowwise() %>%
mutate(word_count = stringr::str_count(dialogue, "\\S+")) %>%
ungroup() %>%
filter(!word_count == 0)
head(damn_lies, 10)
damn_lies %>%
group_by(character) %>%
summarise(total_words = sum(word_count),
average_words = round(mean(word_count)),
total_lines = n()) %>%
arrange(desc(total_words)) %>%
rename(Character = character,
`Total Words` = total_words,
`Average Words` = average_words,
`Total Lines` = total_lines)
stargazer(damn_lies %>%
group_by(character) %>%
summarise(total_words = sum(word_count),
average_words = round(mean(word_count)),
total_lines = n()) %>%
arrange(desc(total_words)) %>%
rename(Character = character,
`Total Words` = total_words,
`Average Words` = average_words,
`Total Lines` = total_lines))
stargazer(tibble::tibble(damn_lies %>%
group_by(character) %>%
summarise(total_words = sum(word_count),
average_words = round(mean(word_count)),
total_lines = n()) %>%
arrange(desc(total_words)) %>%
rename(Character = character,
`Total Words` = total_words,
`Average Words` = average_words,
`Total Lines` = total_lines)), summary = F)
stargazer(tibble::tibble(damn_lies %>%
group_by(character) %>%
summarise(total_words = sum(word_count),
average_words = round(mean(word_count)),
total_lines = n()) %>%
arrange(desc(total_words)) %>%
rename(Character = character,
`Total Words` = total_words,
`Average Words` = average_words,
`Total Lines` = total_lines)), summary = T)
damn_lies <- damn_lies %>%
group_by(character) %>%
summarise(total_words = sum(word_count),
average_words = round(mean(word_count)),
total_lines = n()) %>%
arrange(desc(total_words)) %>%
rename(Character = character,
`Total Words` = total_words,
`Average Words` = average_words,
`Total Lines` = total_lines)
stargazer(
as.data.frame(damn_lies)
, summary = T)
stargazer(as.data.frame(damn_lies),
summary = T,
type = "latex",
header = FALSE,
font.size = "scriptsize")
damn_lies %>%
group_by(character) %>%
summarise(total_words = sum(word_count),
average_words = round(mean(word_count)),
total_lines = n()) %>%
arrange(desc(total_words)) %>%
rename(Character = character,
`Total Words` = total_words,
`Average Words` = average_words,
`Total Lines` = total_lines)
west_wing <- data.frame(unlist(west_wing)) %>%
setNames('text') # Unlist Script as Text
characters <- c('Josh', 'Toby', 'C.J.', 'Donna', 'Sam', 'Leo', 'Bartlet')  # Characters of Interests
character_regex <- paste0("^(", paste0(toupper(characters), collapse = "|"), ")$") #
damn_lies <-  west_wing %>%
mutate(character_line = ifelse(stringr::str_detect(text, character_regex), 1, 0),
empty_row = ifelse(text == '', 1, 0),
first_entry = ifelse(character_line == 1, 1, NA)) %>%
tidyr::fill(first_entry, .direction = 'down') %>%
filter(!is.na(first_entry)) %>%
select(-c(first_entry)) %>%
mutate(group = cumsum(character_line == 1)) %>%
group_by(group) %>%
mutate(to_keep = row_number() < which(empty_row == 1)[1] | is.na(which(empty_row == 1)[1])) %>%
ungroup() %>%
filter(to_keep) %>%
select(text, character_line) %>%
mutate(group = cumsum(character_line == 1)) %>%
group_by(group) %>%
summarise(
character = text[character_line == 1][1],
dialogue  = paste(text[-1], collapse = " "),
.groups = "drop") %>%
rename(id = group) %>%
select(character, dialogue, id) %>%
rowwise() %>%
mutate(word_count = stringr::str_count(dialogue, "\\S+")) %>%
ungroup() %>%
filter(!word_count == 0)
damn_lies %>%
group_by(character) %>%
summarise(total_words = sum(word_count),
average_words = round(mean(word_count)),
total_lines = n()) %>%
arrange(desc(total_words)) %>%
rename(Character = character,
`Total Words` = total_words,
`Average Words` = average_words,
`Total Lines` = total_lines)
gc()
library(dplyr); library(ggplot2); library(gutenbergr); library(stringr)
west_wing_script_location <- "https://raw.githubusercontent.com/JakeTruscott/CSS_POS_UF/main/docs/assets/replication_materials/class_4/supplemental_materials/West_Wing_S1_E21.txt" # Location of txt File on Github Repo
west_wing <- readLines(west_wing_script_location, warn = FALSE) # Read Txt from GitHub Repo
head(west_wing) # Print Head
west_wing <- data.frame(unlist(west_wing)) %>%
setNames('text') # Unlist Script as Text
View(west_wing)
characters <- c('Josh', 'Toby', 'C.J.', 'Donna', 'Sam', 'Leo', 'Bartlet')  # Characters of Interests
character_regex <- paste0("^(", paste0(toupper(characters), collapse = "|"), ")$") #
character_regex
damn_lies <-  west_wing %>%
mutate(character_line = ifelse(stringr::str_detect(text, character_regex), 1, 0)) # If Character Found in Text
View(damn_lies)
damn_lies <-  west_wing %>%
mutate(character_line = ifelse(stringr::str_detect(text, character_regex), 1, 0), # If Character Found in Text
empty_row = ifelse(text == '', 1, 0), # If Row is Empty
first_entry = ifelse(character_line == 1, 1, NA)) #
damn_lies <-  west_wing %>%
mutate(character_line = ifelse(stringr::str_detect(text, character_regex), 1, 0), # If Character Found in Text
empty_row = ifelse(text == '', 1, 0), # If Row is Empty
first_entry = ifelse(character_line == 1, 1, NA)) %>% #
tidyr::fill(first_entry, .direction = 'down') # Fill Down
damn_lies <-  west_wing %>%
mutate(character_line = ifelse(stringr::str_detect(text, character_regex), 1, 0), # If Character Found in Text
empty_row = ifelse(text == '', 1, 0), # If Row is Empty
first_entry = ifelse(character_line == 1, 1, NA)) %>% #
tidyr::fill(first_entry, .direction = 'down') %>% # Fill Down
filter(!is.na(first_entry)) %>% # Remove Empty Rows
select(-c(first_entry)) %>%
mutate(group = cumsum(character_line == 1)) %>%
group_by(group) %>%
mutate(to_keep = row_number() < which(empty_row == 1)[1] | is.na(which(empty_row == 1)[1])) %>%
ungroup() %>%
filter(to_keep) %>% # Removes Empty Lines
select(text, character_line) %>%
mutate(group = cumsum(character_line == 1))
damn_lies <-  west_wing %>%
mutate(character_line = ifelse(stringr::str_detect(text, character_regex), 1, 0), # If Character Found in Text
empty_row = ifelse(text == '', 1, 0), # If Row is Empty
first_entry = ifelse(character_line == 1, 1, NA)) %>% #
tidyr::fill(first_entry, .direction = 'down') %>% # Fill Down
filter(!is.na(first_entry)) %>% # Remove Empty Rows
select(-c(first_entry)) %>%
mutate(group = cumsum(character_line == 1)) %>%
group_by(group) %>%
mutate(to_keep = row_number() < which(empty_row == 1)[1] | is.na(which(empty_row == 1)[1])) %>%
ungroup() %>%
filter(to_keep) %>% # Removes Empty Lines
select(text, character_line) %>%
mutate(group = cumsum(character_line == 1)) %>%
group_by(group) %>%
summarise(
character = text[character_line == 1][1],
dialogue  = paste(text[-1], collapse = " "),
.groups = "drop") %>%
rename(id = group) %>%
select(character, dialogue, id) %>%
rowwise() %>%
mutate(word_count = stringr::str_count(dialogue, "\\S+")) %>% # Count Words
ungroup() %>%
filter(!word_count == 0) # Final Check
head(damn_lies, 10) # Print Sample of Rows
damn_lies %>%
group_by(character) %>% # By Each Character
summarise(total_words = sum(word_count), # Total Words
average_words = round(mean(word_count)), # Average Per Utterance
total_lines = n()) %>% # Total Utterances
arrange(desc(total_words)) %>% # Organize Most to Least
rename(Character = character,
`Total Words` = total_words,
`Average Words` = average_words,
`Total Lines` = total_lines)
dobbs <- get(load('data/class_4/dobbs_19-1392.rdata')) # Load Dobbs
load("C:/Users/jaketruscott/Github/CSS_POLS_UF/docs/assets/replication_materials/class_4/data/dobbs_19-1392.rdata")
View(dobbs)
dobbs %>%
filter(role == 'Justice') %>%
group_by(speaker) %>%
summarise(utterances = n()) %>%
arrange(desc(utterances)) # Utterances
dobbs %>%
filter(role == 'Justice') %>%
group_by(speaker) %>%
summarize(text = paste(text, collapse = " "), .groups = "drop") %>%
tidytext::unnest_tokens(word, text) %>%
group_by(speaker) %>%
summarise(word_count = n(), .groups = 'drop') %>%
arrange(desc(word_count)) # Words Spoken
gutenberg_metadata %>%
filter(title == "Oliver Twist")
oliver_twist <- gutenberg_download(730) # Download Oliver Twist
chapter_ids <-  paste0('(', paste(paste0('CHAPTER ', as.character(as.roman(1:26)), '.' ), collapse = '|'), ')') # Roman Number Chapter IDs
chapter_ids
oliver_twist <- oliver_twist %>%
mutate(chapter_start = ifelse(grepl(chapter_ids, text), 1, 0),  # Identify Chapter Starts
chapter_name = ifelse(chapter_start == 1, paste(text, lead(text)), NA),
chapter_name = ifelse(chapter_start == 1 & !lead(text, 2) == '', paste0(chapter_name, ' ', lead(text, 2)), chapter_name),
chapter_name = trimws(chapter_name)) %>% # Name Chapters
filter(!lag(chapter_start) == 1) %>% # Remove Title Rows
tidyr::fill(chapter_name, .direction = 'down') %>% # Assign Chapter Down
filter(!is.na(chapter_name), !text %in% c('', ' '), !chapter_start == 1) %>% # Remove Header, Empty Rows, Chapter Start Row
rowwise() %>%
filter(!grepl(text, chapter_name, fixed = TRUE)) %>%
select(-c(chapter_start, gutenberg_id))
paste(oliver_twist$text[1:8], collapse = ' ')
oliver_twist <- tibble::as_tibble(
oliver_twist %>%
mutate(chapter_name = trimws(chapter_name),
chapter_name = ifelse(stringr::str_count(chapter_name, "\\S+") > 10,
paste0(stringr::str_c(stringr::str_split(chapter_name, "\\s+", simplify = TRUE)[, 1:10],
collapse = " "), "..."), chapter_name)) %>%
group_by(chapter_name) %>%
summarize(text = paste(text, collapse = " "), .groups = "drop") %>%
tidytext::unnest_tokens(word, text) %>%
group_by(chapter_name) %>%
summarize(
`Word Count` = n(),
`Unique Words` = n_distinct(word),
.groups = "drop"
) %>%
rename(`Chapter Name` = chapter_name)
)  # As Tibble
stargazer::stargazer(oliver_twist, type = 'text', summary = F)
oliver_twist <- gutenberg_download(730) # Download Oliver Twist
library(dplyr)
rm(oliver_twist)
oliver_twist <- gutenbergr::gutenberg_download(730) # Download Oliver Twist
damn_lies_corpus <- quanteda::corpus(damn_lies, text_field = "dialogue") # Create Corpus (Text = 'dialogue')
summary(damn_lies_corpus[1:10]) # Inspect (Just First Couple of Rows)
