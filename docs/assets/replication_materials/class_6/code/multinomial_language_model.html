<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Truscott (Spring 2026)" />


<title>Multinomial Language Model</title>

<script src="multinomial_language_model_files/header-attrs-2.28/header-attrs.js"></script>
<script src="multinomial_language_model_files/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="multinomial_language_model_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="multinomial_language_model_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="multinomial_language_model_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="multinomial_language_model_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="multinomial_language_model_files/navigation-1.1/tabsets.js"></script>
<link href="multinomial_language_model_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="multinomial_language_model_files/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div id="header">



<h1 class="title toc-ignore">Multinomial Language Model</h1>
<h3 class="subtitle">POS6933: Computational Social Science</h3>
<h4 class="author">Truscott (Spring 2026)</h4>

</div>


<hr />
<div id="multinomial-language-model" class="section level2">
<h2>Multinomial Language Model</h2>
<p>The multinomial language model is a probabilistic framework used to
model the distribution of words in a document or collection of
documents. It assumes that each word in a document is drawn
independently from a fixed vocabulary according to a categorical
distribution – i.e., in accordance with the <i>Bag of Words</i>, where
each word has a certain probability of occurring. The model is
``multinomial’’ in that it considers the counts of each word in a
document, rather than just the presence or absence of words. Formally,
for a document represented as a sequence of word counts, the likelihood
of observing the document is given by the multinomial probability mass
function (PMF), which combines the factorial of the total word count
with the product of the probabilities of each word raised to the power
of its observed count. This framework forms the basis for many text
modeling techniques, including Naive Bayes classifiers and topic models
(which we will explore more this week and next…), and provides a
straightforward way to estimate the probability of unseen documents
given observed word frequencies.</p>
<hr />
<p><b>GRS</b> (Ch. 6) uses a simplified three-word vocabulary
<code>(cat, dog, fish)</code> and each document only contains a single
token (i.e., instance of a type). We are going to retains a similar
structure, but add another word to our vocabulary: <br></p>
<div style="text-align:center;">
<p><code>hamburger = (1, 0, 0, 0)</code><br></p>
<p><code>salad = (0, 1, 0, 0)</code><br></p>
<p><code>taco = (0, 0, 1, 0)</code><br></p>
<p><code>nuggets = (0, 0, 0, 1)</code><br></p>
</div>
<p>Recall that this approach accords with the Bag of Words, where words
are drawn individually and independently from a categorical
distribution, where <span class="math inline">\(W_i = \mu\)</span> –
where <span class="math inline">\(\mu\)</span> is <i>a vector containing
the probability of each individual type</i>. For this example, lets say
<span class="math inline">\(\mu =\)</span> (0.3, 0.25, 0.15, 0.3).
Meaning that the probability of each token type being drawn for any
trial is:</p>
<ul>
<li><p><span class="math inline">\(p\)</span>(<code>hamburger</code>) =
0.3</p></li>
<li><p><span class="math inline">\(p\)</span>(<code>salad</code>) =
0.25</p></li>
<li><p><span class="math inline">\(p\)</span>(<code>taco</code>) =
0.15</p></li>
<li><p><span class="math inline">\(p\)</span>(<code>nuggets</code>) =
0.3</p></li>
</ul>
<p>In other words, each word in the document is generated by
independently sampling from these four categories according to their
respective probabilities. Let’s assume we were interested in the
probability of drawing the document (<code>hamburger</code>,
<code>hamburger</code>, <code>taco</code>, <code>nuggets</code>). The
resulting count vector would be (2, 0, 1, 1) – representing 2 instances
of <code>hamburger</code>, 0 instances of <code>salad</code>, and 1
instance of both <code>taco</code> and <code>nuggets</code>.</p>
<p>Recall that the probability mass function for a categorical
distribution is:</p>
<p><span class="math display">\[
p(\mathbf{W}_i \mid \boldsymbol{\mu})
= \prod_{j=1}^J \mu_j^{w_{ij}}
\]</span></p>
<p>which we can generalize for documents that are longer than one word
using the multinomial distribution, where <span
class="math inline">\(\mathbf{M}\)</span> is an integer that controls
the number of tokens (i.e., length of the document):</p>
<p><span class="math display">\[
p(\mathbf{W}_i \mid \boldsymbol{\mu}) =
\frac{M!}{\prod_{j=1}^J W_{ij}!} \prod_{j=1}^J
\mu_{j}^{\mathbf{W}_{ij}}
\]</span></p>
<p>Supplementing our values for the hypothetical document
(<code>hamburger</code>, <code>hamburger</code>, <code>taco</code>,
<code>nuggets</code>), we get:</p>
<p><span class="math display">\[
p(\texttt{H,H,T,N} \mid \mu) =
\frac{4!}{(2_{H}!)(0_{S}!)(1_{T}!)(1_{N}!)}
(0.3_H)^2 (0.25_S)^0 (0.15_T)^1 (0.3_N)^1
\]</span></p>
<p><span class="math display">\[
= \frac{4!}{2!\cdot0!\cdot1!\cdot1!}\quad 0.09 \cdot 1 \cdot 0.15 \cdot
0.3
\]</span></p>
<p><span class="math display">\[
= 12 \cdot 0.00406 \\
\]</span> <span class="math display">\[
p(H,H,T,N \mid \mu) \approx 0.0486
\]</span></p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
