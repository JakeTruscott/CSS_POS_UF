<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Truscott (Spring 2026)" />


<title>Vector Space Model</title>

<script src="vector_space_model_files/header-attrs-2.28/header-attrs.js"></script>
<script src="vector_space_model_files/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="vector_space_model_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="vector_space_model_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="vector_space_model_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="vector_space_model_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="vector_space_model_files/navigation-1.1/tabsets.js"></script>
<link href="vector_space_model_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="vector_space_model_files/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div id="header">



<h1 class="title toc-ignore">Vector Space Model</h1>
<h3 class="subtitle">POS6933: Computational Social Science</h3>
<h4 class="author">Truscott (Spring 2026)</h4>

</div>


<hr />
<div id="vector-space-model" class="section level2">
<h2>Vector Space Model</h2>
<p>While a multinomial language model looks at text as a series of words
and focuses on how likely each word is to appear, a <b>vector space
model</b> treats text as a point in space, letting us measure how
similar two texts are based on distance or direction. In essence, MLM is
all about <i>word probabilities</i> – that is, figuring out which words
are more likely in a document, whereas VSMs leverage <i>linear
algebra</i> to turn text into vectors so we can compare documents based
on their overall content, not just exact word counts.</p>
<p>As you might infer, this forms the key idea behind virtually all
similarity-based measures of text: the assumption that documents sharing
similar features – i.e., whether word frequencies or other vectorized
representations (…) are semantically alike.</p>
<p><b> GSR (Ch. 7) </b> gives a great overview using the <i>Federalist
Papers</i> example to demonstrate how we can use inner products to
articulate similar writing styles – the idea again being that greater
values represent similar documents (or authorship/writing styles). Using
our specific adjustments from the
<a href="https://jaketruscott.github.io/CSS_POS_UF/class_6/multinomial_language_model.html#multinomial-language-model">
Multinomial Language Model</a>, we can show how Madison and Hamilton’s
writing styles are similar than Madison and Jay (and by a considerable
margin):</p>
<p><span class="math display">\[\mathbf{W_{Madison}} \cdot
\mathbf{W_{Hamilton}} = (477, 1, 17, 7, 12) \cdot (861, 13, 102, 374, 1)
\]</span> <span class="math display">\[= (477 \times 861) + (1 \times
13) + (17 \times 102) + (7 \times 374) + (12 \times 1) \]</span> <span
class="math display">\[= 410,697\]</span></p>
<p><span class="math display">\[\mathbf{W_{Madison}} \cdot
\mathbf{W_{Jay}} = (477, 1, 17, 7, 12) \cdot (82, 1, 0, 1, 0, 84)
\]</span> <span class="math display">\[= (477 \times 82) + (1 \times 1)
+ (17 \times 0) + (7 \times 0) + (12 \times 84)\]</span> <span
class="math display">\[= 40,123\]</span></p>
<div id="cosine-similarity" class="section level3">
<h3>Cosine Similarity</h3>
<p>We can use a similar intuition to (again) attempt to discern the
authorship of a disputed essay. However, as <b>GSR</b> note, the
magnitude of the vectors – i.e., the volume of observations we have to
recover an accurate illustration of each authors’ word choice – might
give Hamilton a clear edge due to the sheer volume of word
co-occurrence. This raises an important question: <b>Is similarity
(here, prescribing authorship of disputed documents) best represented by
the volume of word co-occurrence, or the distribution of that
co-occurrence?</b> Put differently, should it matter more that Hamilton
used the four of the five words in our vocabulary more frequently than
Madison, or should it matter more how the distribution of that word
usage matches that in the disputed document? In a perfect world, these
are not mutually-exclusive. However, among higher-dimensional documents
with robust vocabularies, we need something that doesn’t over-inflate
large magnitudes of co-occurrence with similarity. Perhaps the most
intuitive alternative would be to normalize the vectors and assess
cosine similarity – which emphases the direction of the shared features,
rather than simply its length or volume.</p>
<p>Let’s walk through Cosine Similarity using our example that compares
Hamilton and the disputed essay. We will first compute the inner
product, compute the magnitude of those vectors, and then normalize
using cosine similarity.</p>
<p><br></p>
<p><b>Inner Product</b></p>
<p><span class="math display">\[
\mathbf{W}_{Hamilton} \cdot \mathbf{W}_{Disputed} = (861 \times 23) +
(13 \times 1) + (102 \times 0) + (374 \times 0) + (1 \times 2) \quad =
19,818
\]</span> <br> <b>Magnitude of Vectors</b></p>
<p><span class="math display">\[
||\mathbf{W}_{Hamilton}|| = \sqrt{861^2 + 13^2 + 102^2 + 374^2 + 1^2}
\quad \approx 944.33
\]</span> <span class="math display">\[
||\mathbf{W}_{Disputed}||  = \sqrt{23^2 + 1^2 + 0^2 + 0^2 + 2^2} \quad
\approx 23.10
\]</span></p>
<p><br> <b>Cosine Similarity</b></p>
<p><span class="math display">\[
cos(\mathbf{W}_{Hamilton}, \mathbf{W}_{Disputed}) = \frac{19,818}{944.33
\times 23.10} \quad \approx 0.9085
\]</span></p>
<p>Not bad – certainty more convincing that Hamilton authored than with
using MLM. But what happens when we apply the same to Madison?</p>
<p><br></p>
<p><b>Inner Product</b> <span class="math display">\[
\mathbf{W}_{Madison} \cdot \mathbf{W}_{Disputed} = (477 \times 23) + (1
\times 1) + (17 \times 0) + (7 \times 0) + (12 \times 2) \quad = 10,996
\]</span></p>
<p><br> <b>Magnitude of Vectors</b></p>
<p><span class="math display">\[
||\mathbf{W}_{Madison}|| = \sqrt{477^2 + 1^2 + 17^2 + 7^2 + 12^2} \quad
\approx 477.50
\]</span> <br> <b>Cosine Similarity</b></p>
<p><span class="math display">\[
cos(\mathbf{W}_{Madison}, \mathbf{W}_{Disputed}) = \frac{10,996}{477.50
\times 23.10} \quad \approx 0.996
\]</span> Wow! Even though cosine similarity gave much more credence to
the idea that Hamilton may have been the disputed author, normalizing
Madison’s vector as well just effectively removed any doubt that it is
indeed a Madison work. In essence, normalizing the vectors removed the
prioritization of the magnitude found in Hamilton’s vector</p>
</div>
<div id="measuring-distance" class="section level3">
<h3>Measuring Distance</h3>
<p>Another way to measure the (dis)similarity between two documents is
to imagine them as two points in space and calculating the distance
between them. This approach will be of particular importance once we
move to sentence embeddings and analyze similarity in a high-dimensional
space. For now, let’s just recognize that there are a handful of useful
measures (e.g., Euclidean and Manhattan distances) that aren’t entirely
dissimilar from subtracting normalized cosine similarity from 1 (i.e.,
Cosine <i>Distance</i>). Yet, it’s important to emphasize that although
we’re likely to get similar values – or, at least, values representing
substantively similar inferences, the choice of which distance metric to
use is generally a modeling choice (i.e., what we want similarity to
mean), not a mathematical one. Let’s use our values from Hamilton and
the disputed <i>Federalist Paper</i> as an example:</p>
<p><br> <b>Euclidean</b> <span class="math display">\[
||\mathbf{W}_{Hamilton}|| - ||\mathbf{W}_{Disputed}|| =
\sqrt{\sum^j_{j=1}(W_{Hamilton}-W_{Disputed})^2}
\]</span> <span class="math display">\[
||\mathbf{W}_{Hamilton}|| - ||\mathbf{W}_{Disputed}|| = \sqrt{838^2 +
12^2 + 102^2 + 374^2 + (-1)^2} \\ = \sqrt{852,669} \\\quad \approx
923.36
\]</span> <br> <b>Minkowski</b> (<span class="math inline">\(p =
3\)</span> &amp; <span class="math inline">\(j =\)</span> size of
vocabulary) <span class="math display">\[
d_p(W_{Hamilton}, W_{Disputed}) = (\sum^j_{j=1}|W_{Hamilton,j} -
W_{Disputed, j}|^p)^{\frac{1}{p}}
\]</span> <span class="math display">\[
d_p(W_{Hamilton}, W_{Disputed}) = (|838|^3 + |12|^3 + |102|^3 + |374|^3
+ |1|^3)^{\frac{1}{3}} \\ = (641,223,033)^{\frac{1}{3}} \\ \approx
867.86  
\]</span></p>
<p><br> <b>Manhattan</b> (Just Sum of Absolute Values because <span
class="math inline">\(p\)</span> = 1) <span class="math display">\[
d_p(W_{Hamilton}, W_{Disputed}) = |838| + |12| + |102| + |374| + |(-1)|
\\ \quad \approx 1,327
\]</span></p>
<p><br></p>
</div>
<div id="tf-idf-weighting" class="section level3">
<h3>TF-IDF Weighting</h3>
<p>Universities frequently employ a point-based or index system for
deciding admission to its graduate and undergraduate programs.
Notwithstanding recent Supreme Court decisions (particularly those
concerning the consideration of race and ethnicity), universities
frequently employ these systems because they allow admissions committees
to evaluate applicants in a structured, comparative manner while still
preserving a degree of discretion. By converting heterogeneous
credentials – such as grades, standardized test scores, coursework
rigor, extracurricular involvement, and personal statements – into a
common metric, point-based or index systems facilitate consistency and
transparency in large-scale admissions processes. The central problem in
evaluating large numbers of applicants is not merely identifying which
attributes are present, but determining which attributes are
informative. Some features appear in nearly every application – e.g.,
completion of basic coursework or participation in common
extracurricular activities – and therefore do little to distinguish
among candidates. Other features are rarer or context-specific as a
result may convey substantially more information about an applicant’s
preparation or fit. Treating all attributes as equally important risks
overvaluing ubiquitous signals while under-weighting those that are
genuinely discriminating.</p>
<p>This central problem is not far removed from ours. Given an expansive
vocabulary, how should we discriminate between two documents? Up to this
point, we have effectively assumed that – after removing stopwords and
other terms known to contribute little substantive information – all
remaining words should be treated as equally informative. Under this
assumption, similarity is driven by word co-occurrence, while difference
is driven by word discrimination. Yet this approach risks two opposing
errors. On the one hand, it may overstate the importance of documents
that share a large number of common terms drawn from a high-frequency
vocabulary. On the other, it may exaggerate differences based on the
presence of a single word (or small series of words) that appears in
only one document but carries little intrinsic meaning or substantive
relevance.</p>
<p>Directly prescribing informative value to specific words constitutes
a weighting scheme, whereby the mathematics underlying similarity or
distance calculations assigns unequal numerical importance to terms in
the vocabulary based on their assumed informational content. As
<b>GSR</b> note, “the common theme in computational linguistics
literature is that the greatest signals from words are those in the
<i>Goldilocks region</i> – neither too rare nor too frequent.” Very
common words are glue that hold documents together – but they generally
do a poor job at telling you what a document is about. Rare words
certainly help you discriminate across documents, but their infrequency
makes it difficult to assess any generalizations. The result is in the
middle – which we can explore using <b>term frequency inverse frequency
weighting</b> or <b>TF-IDF</b>.</p>
<p>TF–IDF attempts to prioritize terms that are frequent within a given
document but rare across the corpus as a whole. After computing a DFM,
tf–idf rescales each term by its inverse document frequency, which
down-weights terms that appear in many documents. As a result, words
that occur frequently in individual documents while remaining relatively
uncommon in the broader corpus receive greater weight. Terms that
satisfy both conditions occupy a “Goldilocks” zone, while terms that
violate both conditions are penalized. As the book notes, there are a
handful of ways to specify tf-idf, though we will use:</p>
<p><span class="math display">\[
W^{tf-idf}_{ij} = W_{ij} * log\frac{N}{n_j}
\]</span> Where…</p>
<p><span class="math display">\[
N = \text{Number of Documents in Corpus} \\
n_j = \text{Number of Documents Containing Word } j \\
W_{ij} = \text{Word Count} \\
log\frac{N}{n_j} = \text{Penalty for Frequent Words} \\
\]</span></p>
<p><b>Hamilton (No TF-IDF) </b></p>
<p><img src="vector_space_model_files/figure-html/hamilton_reg-1.png" width="672" /></p>
<p><br> <b>Hamilton (TF-IDF)</b></p>
<p><img src="vector_space_model_files/figure-html/hamilton_tfidf-1.png" width="672" /></p>
<p><br></p>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
