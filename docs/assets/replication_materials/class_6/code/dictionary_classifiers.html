<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Truscott (Spring 2026)" />


<title>Dictionaries</title>

<script src="dictionary_classifiers_files/header-attrs-2.28/header-attrs.js"></script>
<script src="dictionary_classifiers_files/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="dictionary_classifiers_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="dictionary_classifiers_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="dictionary_classifiers_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="dictionary_classifiers_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="dictionary_classifiers_files/navigation-1.1/tabsets.js"></script>
<link href="dictionary_classifiers_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="dictionary_classifiers_files/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div id="header">



<h1 class="title toc-ignore">Dictionaries</h1>
<h3 class="subtitle">POS6933: Computational Social Science</h3>
<h4 class="author">Truscott (Spring 2026)</h4>

</div>


<hr />
<div id="dictionaries" class="section level2">
<h2>Dictionaries</h2>
<p>There are few intellectual exercises more demanding (or more
burdensome…) than studying variation in language. Most modern English
dictionaries estimate the language to contain no fewer than 170,000
words, a figure that continues to evolve as some terms fall into
obsolescence while others are continually introduced (often to the
dismay of those who find Generation Alpha brain rot slang less than
inspiring…). Matters become even more complicated when we consult a
thesaurus and recognize that nearly every word possesses multiple
synonyms, each differing in appropriateness depending on meaning, tense,
register, and broader syntactic context.</p>
<p>For the moment, we will set aside many of these complexities until we
turn to vectorized word embeddings in high-dimensional spaces. For now,
let us assume that words – irrespective of tense or usage – possess
localized and singular meanings. Consider the following sentence:</p>
<p><span class="math display">\[
\text{I loved the new restaurant; the food was delicious and the service
was fantastic}
\]</span> After reducing complexity using the same approach as
<a href="https://jaketruscott.github.io/CSS_POS_UF/class_5/bag_of_words.html">our
previous class</a>, we are left with <i>love new restaurant food
delicious service fantastic</i>.While we might have been able to infer
from just reading the original sentence that the implied <b> rhetorical
sentiment</b> (i.e., the attitudinal or affective quality of text) was
certainly <i>positive</i> (as opposed to <i>neutral, negative</i>, or
some alternative <b>classification</b>), reducing the complexity we are
left with two words (<i>glad &amp; enjoy</i>) that still reflect a
<i>positive</i> sentiment, while <i>movie</i> appears to not relay a
perceivable sentiment. In its most basic form, we can simply assert that
because there are (2) <i>positive</i> words and (0) <i>negative</i>
words, the sentence is <i>positive</i>!</p>
<p>Now let’s consider another sentence:</p>
<p><span class="math display">\[
\text{The movie was a disappointment; the plot was confusing and the
acting was poor}
\]</span> Much like the first sentence, we could probably infer the
<i>negative</i> intent, but removing complexity again further reinforces
our belief (<i>movie disappointment plot confuse act poor</i>). The
terms <i>disappointment, confuse,</i> and <i>poor</i> offer a
preponderance of evidence that the sentence’s implied sentiment is
<i>negative</i></p>
<p>But what about a sentence like this:</p>
<p><span class="math display">\[
\text{The concert had amazing visuals and energy, but the sound quality
was inconsistent}
\]</span> Which produces <i>concert amaze visual energy sound quality
inconsistent</i>. Suddenly our ability to consider sentiment at face
value is a bit more challenging – surely we could make the argument that
the author certainly enjoyed the concert, but it is not a full-throated
endorsement due to the inconsistent sound quality. Assessing sentiment
at the word level (<i>concert amaze visual energy sound quality
inconsistent</i>) now requires greater diligence – as we could
reasonably assert that although the sentence contains at least one
<i>positive</i> term (<i>amaze</i>) and one <i>negative</i> term
(<i>inconsistent</i>) whether and how we assess meaning to the remaining
terms with debatable classifications (<i>energy &amp; quality</i>),
could have an important impact on our ability to classify this sentence
correctly, as well as any others where we employ that approach.</p>
<p>This approach is at the core of dictionary methods – perhaps the best
introductory approach to understanding how we can derive meaning (e.g.,
rhetorical sentiment) from text. In short, dictionary methods rely on a
pre-defined lexicon where each word (or n-gram) is assigned to one or
more categories, such as <i>positive</i> or <i>negative</i> sentiment.
The strength of this approach lies in having a large, carefully curated
vocabulary whose classifications are both theoretically grounded and
defensable (i.e., terms that you define as + or - are truly such.) By
counting the frequency of words in each category, we can estimate the
presence and intensity of particular meanings or sentiments across
sentences, passages, and documents.</p>
<p>Before I demonstrate a handful of the existing dictionary methods in
<code>R</code>, I want to emphasize (4) key points about dictionary
classifiers (which I already touch on briefly in the previous note):</p>
<ol style="list-style-type: decimal">
<li><p>Dictionary classifiers, while rather simple and intuitive, can
nevertheless provide robust classification power. Especially among
documents retaining authentic discursive properties – i.e., authors
refrain from literary tools like misdirection, sarcasm, or other
inauthentic speech, a dictionary strategy provides a lot of upside for
considerably little technical effort.</p></li>
<li><p>However, much of that validity relies on the ability of
researchers to construct dense lexicons. Much like anything in
statistical analyses, small-N problems easily permeate dictionary
approaches when the size of variety of the lexicon is insufficient to
capture the variance of the documents themselves.</p></li>
<li><p>Moreover, while a dense dictionary is certainly important,
paramount to such is constructing categorical classifications (e.g.,
positive or negative) that are both authentic and defensible. For
example, terms like <i>happy</i> and <i>joyous</i> are (almost always)
associated with <i>positive</i> sentiments, while terms like
<i>depressing</i> or <i>hateful</i> are certainly more negative.
Misidentifying these terms will surely impact your ability to make valid
classifications.</p></li>
<li><p>Finally, and in a similar vein, dictionary methods are sensibly
plagued by the same concern as the bag of words, more generally. In
particular, words have associated meaning based on tense and conditional
usage. For instance, <i>happy</i> is certainly <i>positive</i> – but
what if the sentence actually reads <i>I was not happy at all</i>.
Suddenly that very negative sentence may be misclassified as a
<i>positive</i> sentence based solely on the classification label for
<i>happy</i>. Much of these concerns (as with other areas concerning the
bag of words) can be improved given more robust methods, including the
incorporation of inverses (<i>not</i>) and n-grams.</p></li>
</ol>
<div id="sentiment-analysis-using-dictionary-methods-examples-in-r"
class="section level3">
<h3>Sentiment Analysis Using Dictionary Methods (Examples in
<code>R</code>)</h3>
<p>Below I provide a handful of sandboxed dictionary methods – all of
which will rely on the same collection of strings. In particular, I will
focus just on three methods: Bing (Word <span
class="math inline">\(\rightarrow\)</span> Class), Afinn (Word <span
class="math inline">\(\rightarrow\)</span> Scalar), and Sentimentr
(Sentiment = Polarity x Valence).</p>
<pre class="r"><code>strings &lt;- c(&#39;This decision is excellent, fair, and clearly the right outcome&#39;, 
             &#39;The opinion is good and persuasive, even if it is not perfect&#39;, 
             &#39;The ruling has some good points but also several serious flaws&#39;, 
             &#39;The decision is bad and poorly reasoned&#39;, 
             &#39;This opinion is terrible, deeply unfair, and completely wrong&#39;)

strings &lt;- tibble(
  doc_id = seq_along(strings),
  text = strings) 

strings_tokens &lt;- strings %&gt;% # Convert to tibble
  tidytext::unnest_tokens(word, text) # Convert to Unnested Tokens

head(strings_tokens)</code></pre>
<pre><code>## # A tibble: 6 × 2
##   doc_id word     
##    &lt;int&gt; &lt;chr&gt;    
## 1      1 this     
## 2      1 decision 
## 3      1 is       
## 4      1 excellent
## 5      1 fair     
## 6      1 and</code></pre>
<p><br></p>
<div id="bing" class="section level4">
<h4>Bing</h4>
<p>The <strong>Bing</strong> Dictionary is a sentiment lexicon widely
used for binary sentiment classification. It assigns words to one of two
categories (<em>positive</em> or <em>negative</em>) and contains roughly
6,800 sentiment-labeled terms (approx. 2,000 positive and 4,800
negative)</p>
<pre class="r"><code>bing_dictionary &lt;- tidytext::get_sentiments(&quot;bing&quot;)

bing_dictionary %&gt;%
  group_by(sentiment) %&gt;%
  slice_sample(n = 3) %&gt;%
  ungroup() %&gt;%
  arrange(sentiment) # Sample BING</code></pre>
<pre><code>## # A tibble: 6 × 2
##   word        sentiment
##   &lt;chr&gt;       &lt;chr&gt;    
## 1 disapprove  negative 
## 2 forbidden   negative 
## 3 egotistical negative 
## 4 complements positive 
## 5 galore      positive 
## 6 appreciate  positive</code></pre>
<pre class="r"><code>strings_tokens %&gt;%
  inner_join(tidytext::get_sentiments(lexicon = &#39;bing&#39;), by = &#39;word&#39;) %&gt;%
  count(doc_id, sentiment) %&gt;%
  left_join(strings, by = &#39;doc_id&#39;) %&gt;%
  select(text, sentiment, n)</code></pre>
<pre><code>## # A tibble: 7 × 3
##   text                                                           sentiment     n
##   &lt;chr&gt;                                                          &lt;chr&gt;     &lt;int&gt;
## 1 This decision is excellent, fair, and clearly the right outco… positive      4
## 2 The opinion is good and persuasive, even if it is not perfect  positive      2
## 3 The ruling has some good points but also several serious flaws negative      1
## 4 The ruling has some good points but also several serious flaws positive      1
## 5 The decision is bad and poorly reasoned                        negative      2
## 6 The decision is bad and poorly reasoned                        positive      1
## 7 This opinion is terrible, deeply unfair, and completely wrong  negative      2</code></pre>
<p><br></p>
</div>
<div id="afinn" class="section level4">
<h4>AFINN</h4>
<p>The <strong>AFINN</strong> lexicon is designed to capture
<strong>both the direction and intensity of sentiment</strong>. Unlike
binary lexicons such as Bing, AFINN assigns each word a numeric
sentiment score, typically ranging from <strong>–5 (strongly
negative)</strong> to <strong>+5 (strongly positive)</strong>. The
dictionary contains roughly 2,500–3,400 terms.</p>
<pre class="r"><code>afinn_dictionary &lt;- tidytext::get_sentiments(&quot;afinn&quot;) # Afinn Dictionary

afinn_dictionary %&gt;% 
  group_by(value) %&gt;%
  slice_sample(n = 1) %&gt;%
  ungroup() %&gt;%
  arrange(value) %&gt;%
  print(n = 11) # Sample Words (Value -5 to 5)</code></pre>
<pre><code>## # A tibble: 11 × 2
##    word        value
##    &lt;chr&gt;       &lt;dbl&gt;
##  1 bastards       -5
##  2 pissed         -4
##  3 catastrophe    -3
##  4 touting        -2
##  5 overweight     -1
##  6 some kind       0
##  7 attracted       1
##  8 inspires        2
##  9 gallant         3
## 10 masterpiece     4
## 11 superb          5</code></pre>
<pre class="r"><code>strings_tokens %&gt;%
  inner_join(tidytext::get_sentiments(lexicon = &#39;afinn&#39;), by = &#39;word&#39;) %&gt;%
  count(doc_id, value) %&gt;%
  left_join(strings, by = &#39;doc_id&#39;) %&gt;%
  select(text, value, n)</code></pre>
<pre><code>## # A tibble: 8 × 3
##   text                                                            value     n
##   &lt;chr&gt;                                                           &lt;dbl&gt; &lt;int&gt;
## 1 This decision is excellent, fair, and clearly the right outcome     1     1
## 2 This decision is excellent, fair, and clearly the right outcome     2     1
## 3 This decision is excellent, fair, and clearly the right outcome     3     1
## 4 The opinion is good and persuasive, even if it is not perfect       3     2
## 5 The ruling has some good points but also several serious flaws      3     1
## 6 The decision is bad and poorly reasoned                            -3     1
## 7 This opinion is terrible, deeply unfair, and completely wrong      -3     1
## 8 This opinion is terrible, deeply unfair, and completely wrong      -2     2</code></pre>
</div>
<div id="sentimentr" class="section level4">
<h4>SentimentR</h4>
<p><strong>SentimentR</strong> improves on simple dictionary classifiers
by explicitly modeling context and valence shifters. Rather than relying
solely on raw word counts, <strong>sentimentr</strong> computes
sentiment at the sentence level, accounting for how nearby words modify
sentiment expression. At its core, it uses a BING-style polarity lexicon
(Where words have a singular classification) combined with rule-based
adjustments for <strong>negators</strong> (e.g., <em>not, never</em>,
etc.), <strong>amplifiers</strong> (e.g., <em>very, extremely,</em>
etc.), and <strong>adversarial conjunctions</strong> (e.g.,
<em>but</em>). The result is the base polarity (BING-style score) times
a valence multiplier that adjusts for sentence hueristics (ex:
<em>good</em> = 1x, <em>not good</em> = -1x, <em>barely good</em> =
0.5x, etc.) – where negation doesn’t invariably flip the sign, but
rather it will scale the intensity.</p>
<pre class="r"><code>strings %&gt;%
  mutate(sentiment = sentimentr::sentiment_by(text)$ave_sentiment)</code></pre>
<pre><code>## # A tibble: 5 × 3
##   doc_id text                                                          sentiment
##    &lt;int&gt; &lt;chr&gt;                                                             &lt;dbl&gt;
## 1      1 This decision is excellent, fair, and clearly the right outc…     0.885
## 2      2 The opinion is good and persuasive, even if it is not perfect     0    
## 3      3 The ruling has some good points but also several serious fla…    -0.460
## 4      4 The decision is bad and poorly reasoned                          -0.340
## 5      5 This opinion is terrible, deeply unfair, and completely wrong    -0.667</code></pre>
</div>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
