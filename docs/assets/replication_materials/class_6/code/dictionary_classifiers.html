<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Truscott (Spring 2026)" />


<title>Dictionaries</title>

<script src="dictionary_classifiers_files/header-attrs-2.28/header-attrs.js"></script>
<script src="dictionary_classifiers_files/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="dictionary_classifiers_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="dictionary_classifiers_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="dictionary_classifiers_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="dictionary_classifiers_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="dictionary_classifiers_files/navigation-1.1/tabsets.js"></script>
<link href="dictionary_classifiers_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="dictionary_classifiers_files/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div id="header">



<h1 class="title toc-ignore">Dictionaries</h1>
<h3 class="subtitle">POS6933: Computational Social Science</h3>
<h4 class="author">Truscott (Spring 2026)</h4>

</div>


<hr />
<div id="dictionaries" class="section level2">
<h2>Dictionaries</h2>
<p>There are few intellectual exercises more demanding (or more
burdensome…) than studying variation in language. Most modern English
dictionaries estimate the language to contain no fewer than 170,000
words, a figure that continues to evolve as some terms fall into
obsolescence while others are continually introduced (often to the
dismay of those who find Generation Alpha brain rot slang less than
inspiring…). Matters become even more complicated when we consult a
thesaurus and recognize that nearly every word possesses multiple
synonyms, each differing in appropriateness depending on meaning, tense,
register, and broader syntactic context.</p>
<p>For the moment, we will set aside many of these complexities until we
turn to vectorized word embeddings in high-dimensional spaces. For now,
let us assume that words – irrespective of tense or usage – possess
localized and singular meanings. Consider the following sentence:</p>
<p><span class="math display">\[
\text{I loved the new restaurant; the food was delicious and the service
was fantastic}
\]</span> After reducing complexity using the same approach as
<a href="https://jaketruscott.github.io/CSS_POS_UF/class_5/bag_of_words.html">our
previous class</a>, we are left with <i>love new restaurant food
delicious service fantastic</i>.While we might have been able to infer
from just reading the original sentence that the implied <b> rhetorical
sentiment</b> (i.e., the attitudinal or affective quality of text) was
certainly <i>positive</i> (as opposed to <i>neutral, negative</i>, or
some alternative <b>classification</b>), reducing the complexity we are
left with two words (<i>glad &amp; enjoy</i>) that still reflect a
<i>positive</i> sentiment, while <i>movie</i> appears to not relay a
perceivable sentiment. In its most basic form, we can simply assert that
because there are (2) <i>positive</i> words and (0) <i>negative</i>
words, the sentence is <i>positive</i>!</p>
<p>Now let’s consider another sentence:</p>
<p><span class="math display">\[
\text{The movie was a disappointment; the plot was confusing and the
acting was poor.}
\]</span> Much like the first sentence, we could probably infer the
<i>negative</i> intent, but removing complexity again further reinforces
our belief (<i>movie disappointment plot confuse act poor</i>). The
terms <i>disappointment, confuse,</i> and <i>poor</i> offer a
preponderance of evidence that the sentence’s implied sentiment is
<i>negative</i></p>
<p>But what about a sentence like this:</p>
<p><span class="math display">\[
\text{The concert had amazing visuals and energy, but the sound quality
was inconsistent}
\]</span> Which produces <i>concert amaze visual energy sound quality
inconsistent</i>. Suddenly our ability to consider sentiment at face
value is a bit more challenging – surely we could make the argument that
the author certainly enjoyed the concert, but it is not a full-throated
endorsement due to the inconsistent sound quality. Assessing sentiment
at the word level (<i>concert amaze visual energy sound quality
inconsistent</i>) now requires greater diligence – as we could
reasonably assert that although the sentence contains at least one
<i>positive</i> term (<i>amaze</i>) and one <i>negative</i> term
(<i>inconsistent</i>) whether and how we assess meaning to the remaining
terms with debatable classifications (<i>energy &amp; quality</i>),
could have an important impact on our ability to classify this sentence
correctly, as well as any others where we employ that approach.</p>
<p>This approach is at the core of dictionary methods – perhaps the best
introductory approach to understanding how we can derive meaning (e.g.,
rhetorical sentiment) from text. In short, dictionary methods rely on a
pre-defined lexicon where each word (or n-gram) is assigned to one or
more categories, such as <i>positive</i> or <i>negative</i> sentiment.
The strength of this approach lies in having a large, carefully curated
vocabulary whose classifications are both theoretically grounded and
defensable (i.e., terms that you define as + or - are truly such.) By
counting the frequency of words in each category, we can estimate the
presence and intensity of particular meanings or sentiments across
sentences, passages, and documents.</p>
<p>Before I demonstrate a handful of the existing dictionary methods in
<code>R</code>, I want to emphasize (4) key points about dictionary
classifiers (which I already touch on briefly in the previous note):</p>
<ol style="list-style-type: decimal">
<li><p>Dictionary classifiers, while simple, can nevertheless provide
robust classification power. Especially among documents retaining
authentic discursive properties – i.e., authors refrain from literary
tools like misdirection, sarcasm, or other inauthentic speech, a
dictionary strategy provides a lot of upside for considerably little
technical effort.</p></li>
<li><p>However, much of that validity relies on the ability of
researchers to construct dense lexicons. Much like anything in
statistical analyses, small-N problems easily permeate dictionary
approaches when the size of variety of the lexicon is insufficient to
capture the variance of the documents themselves.</p></li>
<li><p>Moreover, while a dense dictionary is certainly important,
paramount to such is constructing categorical classifications (e.g.,
positive or negative) that are both authentic and defensible. For
example, terms like <i>happy</i> and <i>joyous</i> are (almost always)
associated with <i>positive</i> sentiments, while terms like
<i>depressing</i> or <i>hateful</i> are certainly more negative.
Misidentifying those terms will surely impact your ability to make valid
classifications.</p></li>
<li><p>Finally, and in a similar vein, dictionary methods are sensibly
plagued by the same concern as the bag of words, more generally. In
particular, words have associated meaning based on tense and conditional
usage. For instance, <i>happy</i> is certainly <i>positive</i> – but
what if the sentence actually reads <i>I was not happy at all</i>.
Suddenly that very negative sentence may be misclassified as a
<i>positive</i> sentence based solely on the classification label for
<i>happy</i>. Much of these concerns (as with other areas concerning the
bag of words) can be improved given more robust methods, including the
incorporation of inverses (<i>not</i>) and n-grams.</p></li>
</ol>
<div id="dictionary-methods-examples-in-r" class="section level3">
<h3>Dictionary Methods (Examples in <code>R</code>)</h3>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
