---
title: "Creating a Corpus"
subtitle: "POS6933: Computational Social Science"
author: "Truscott (Spring 2026)"
output:
  html_document:
    self_contained: false
    layout: null
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)

library(dplyr); library(ggplot2); library(ggtext); library(cowplot)

```

------------------------------------------------------------------------

A <code>corpus</code> is a structured collection of text documents. Using packages like <code>quanteda</code> and <code>tm</code>, you can create a corpus from raw text data (like a vector of strings or a column in a dataframe). Once your text is in a corpus, you can easily perform text analysis such as tokenization, creating document-feature matrices, and calculating word frequencies.

Below are two ways to create a corpus in <code>R</code> -- I am not partial to either, though the latter will be a bit more intuitive (I think) for adding metadata. We'll use the same data for both. 

### Using <code>tm</code>

```{r tm, message=FALSE, warning=FALSE}

library(tm) # Load tm

texts <- c(
  "The quick brown fox jumps over the lazy dog.",
  "Data science is revolutionizing the way we analyze information.",
  "Text analysis in R is fun and informative!"
) # Sample Texts (as vector)

tm_corpus <- tm::VCorpus(VectorSource(texts)) # Create Corpus from texts

tm::inspect(tm_corpus) # Inspect

tm_corpus_clean <- tm::tm_map(tm_corpus, content_transformer(tolower)) # Convert All to Lowercase
tm_corpus_clean <- tm::tm_map(tm_corpus_clean, removePunctuation) # Remove Punctuation
tm_corpus_clean <- tm::tm_map(tm_corpus_clean, removeNumbers) # Remove Numbers
tm_corpus_clean <- tm::tm_map(tm_corpus_clean, removeWords, stopwords("english")) # Remove English Stopwords

tm::inspect(tm_corpus_clean) # Notice How A Ton of Characters Are Now Gone?

```
<br>

### Using <code>quanteda</code>


```{r quanteda, message=FALSE, warning=FALSE}
library(quanteda) # Load Quanteda

texts_with_meta <- tibble(
  doc_id = c("sentence_1", "sentence_2", "sentence_3"),
  text = texts, 
  author = c('Josh', 'Leo', 'Toby'),
  date = as.Date(c("2025-01-01", "2025-01-02", "2025-01-03"))
) # Create Metadata for Texts (Same as tm example!)

quanteda_corpus <- corpus(texts_with_meta, text_field = "text")

summary(quanteda_corpus) # Inspect the Corpus

```

### Example: Lies, Damn Lies, and Statistics (2000)

```{r damn_lies, include=FALSE}
west_wing_script_location <- "https://raw.githubusercontent.com/JakeTruscott/CSS_POS_UF/main/docs/assets/replication_materials/class_4/supplemental_materials/West_Wing_S1_E21.txt"
west_wing <- readLines(west_wing_script_location, warn = FALSE) # Read Txt from GitHub Repo
west_wing <- data.frame(unlist(west_wing)) %>%
  setNames('text')
characters <- c('Josh', 'Toby', 'C.J.', 'Donna', 'Sam', 'Leo', 'Bartlet')
character_regex <- paste0("^(", paste0(toupper(characters), collapse = "|"), ")$")

damn_lies <-  west_wing %>%
    mutate(character_line = ifelse(stringr::str_detect(text, character_regex), 1, 0), 
           empty_row = ifelse(text == '', 1, 0), 
           first_entry = ifelse(character_line == 1, 1, NA)) %>%
    tidyr::fill(first_entry, .direction = 'down') %>%
    filter(!is.na(first_entry)) %>%
    select(-c(first_entry)) %>%
    mutate(group = cumsum(character_line == 1)) %>%
    group_by(group) %>%
    mutate(to_keep = row_number() < which(empty_row == 1)[1] | is.na(which(empty_row == 1)[1])) %>%
    ungroup() %>%
    filter(to_keep) %>%
    select(text, character_line) %>%
    mutate(group = cumsum(character_line == 1)) %>%
    group_by(group) %>%
    summarise(
    character = text[character_line == 1][1],
    dialogue  = paste(text[-1], collapse = " "),
    .groups = "drop") %>%
    rename(id = group) %>%
    select(character, dialogue, id) %>%
    rowwise() %>%
    mutate(word_count = stringr::str_count(dialogue, "\\S+")) %>%
    ungroup() %>%
    filter(!word_count == 0)


```


Let's use the same example from the West Wing episode <em>Lies, Damn Lies and Statistics</em> (2000). Recall that our data was organized such that -- for every character we care about -- we have a single dataframe listing the associated character and their dialogue, as well as other information related to word count and dialogue order throughout the episode.

```{r print_damn_lies}

head(damn_lies, 10)

```

Let's use <code>quanteda</code> to construct a corpus from <em>Lies, Damn Lies and Statistics</em>: 

```{r corpus_damn_lies}

damn_lies_corpus <- quanteda::corpus(damn_lies, text_field = "dialogue") # Create Corpus (Text = 'dialogue')

summary(damn_lies_corpus[1:10]) # Inspect (Just First Couple of Rows)

```

